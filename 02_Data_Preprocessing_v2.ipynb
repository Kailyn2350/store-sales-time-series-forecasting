{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f390897",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e65a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03677d5c",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ import**í•©ë‹ˆë‹¤:\n",
    "- `pandas`: ë°ì´í„° ì¡°ì‘ ë° ë¶„ì„\n",
    "- `numpy`: ìˆ˜ì¹˜ ê³„ì‚° (sin, cos ë“±)\n",
    "- `warnings.filterwarnings('ignore')`: ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€ (í•™ìŠµ ê³¼ì • ì¤‘ ë¶ˆí•„ìš”í•œ ê²½ê³  ì œê±°)\n",
    "\n",
    "ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ ì—†ìœ¼ë©´ ì´í›„ì˜ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ **ê°€ì¥ ë¨¼ì € ì‹¤í–‰**ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ef8a0",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef91c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3000888, 6)\n",
      "Test shape: (28512, 5)\n",
      "\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "holidays = pd.read_csv('holidays_events.csv')\n",
    "oil = pd.read_csv('oil.csv')\n",
    "transactions = pd.read_csv('transactions.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\në°ì´í„° ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae6b69",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "Kaggle ê²½ìŸì˜ ëª¨ë“  **ì›ë³¸ CSV íŒŒì¼ë“¤ì„ ë¡œë“œ**í•©ë‹ˆë‹¤:\n",
    "- `train.csv`: í•™ìŠµ ë°ì´í„° (3,626,896 í–‰) - storeë³„, dateë³„ sales í¬í•¨\n",
    "- `test.csv`: ì˜ˆì¸¡í•´ì•¼ í•  ë°ì´í„° - salesê°€ ì—†ìŒ\n",
    "- `stores.csv`: ë§¤ì¥ ì •ë³´ (type, cluster ë“±)\n",
    "- `holidays_events.csv`: íœ´ì¼/ì´ë²¤íŠ¸ ì •ë³´\n",
    "- `oil.csv`: ì¼ì¼ ìœ ê°€ ë°ì´í„°\n",
    "- `transactions.csv`: ì¼ì¼ ê±°ë˜ ê±´ìˆ˜\n",
    "\n",
    "ê° CSVì˜ **í¬ê¸°ë¥¼ ì¶œë ¥**í•˜ì—¬ ë°ì´í„° ë¡œë“œê°€ ì •ìƒì ìœ¼ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82070bbd",
   "metadata": {},
   "source": [
    "## 3. ë‚ ì§œ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0358aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ê¸°ê°„: 2013-01-01 00:00:00 ~ 2017-08-15 00:00:00\n",
      "Test ê¸°ê°„: 2017-08-16 00:00:00 ~ 2017-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# ë‚ ì§œë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "\n",
    "print(f\"Train ê¸°ê°„: {train['date'].min()} ~ {train['date'].max()}\")\n",
    "print(f\"Test ê¸°ê°„: {test['date'].min()} ~ {test['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdaa10",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ë¬¸ìì—´ë¡œ ì €ì¥ëœ 'date' ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜**í•©ë‹ˆë‹¤:\n",
    "- `pd.to_datetime()`: ë‚ ì§œ ë¬¸ìì—´ì„ Python datetime ê°ì²´ë¡œ ë³€í™˜\n",
    "- ì´ë ‡ê²Œ ë³€í™˜í•´ì•¼ `.dt` ì†ì„±ìœ¼ë¡œ ì—°, ì›”, ì¼, ìš”ì¼ ë“±ì„ ì¶”ì¶œí•  ìˆ˜ ìˆìŒ\n",
    "- ì‹œê³„ì—´ ë¶„ì„ì—ì„œ **í•„ìˆ˜ì ì¸ ì „ì²˜ë¦¬ ë‹¨ê³„**\n",
    "\n",
    "ì˜ˆì‹œ: `'2013-01-01'` â†’ `Timestamp('2013-01-01 00:00:00')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf45003",
   "metadata": {},
   "source": [
    "## 4. ë‚ ì§œ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a708d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì¶”ì¶œëœ ë‚ ì§œ íŠ¹ì„±:\n",
      "        date  year  month  day  dayofweek  month_sin  month_cos\n",
      "0 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "1 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "2 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "3 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "4 2013-01-01  2013      1    1          1        0.5   0.866025\n"
     ]
    }
   ],
   "source": [
    "def extract_date_features(df):\n",
    "    \"\"\"ë‚ ì§œì—ì„œ ì—¬ëŸ¬ íŠ¹ì„± ì¶”ì¶œ\"\"\"\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
    "    df['is_quarter_start'] = df['date'].dt.is_quarter_start.astype(int)\n",
    "    df['is_quarter_end'] = df['date'].dt.is_quarter_end.astype(int)\n",
    "    \n",
    "    # âœ“ ì¶”ê°€: Cyclical íŠ¹ì„± (ì‚¼ê°í•¨ìˆ˜ ë³€í™˜)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Train, Testì— íŠ¹ì„± ì¶”ì¶œ\n",
    "train = extract_date_features(train)\n",
    "test = extract_date_features(test)\n",
    "\n",
    "print(\"\\nì¶”ì¶œëœ ë‚ ì§œ íŠ¹ì„±:\")\n",
    "print(train[['date', 'year', 'month', 'day', 'dayofweek', 'month_sin', 'month_cos']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8d46d",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ë‚ ì§œì—ì„œ ìœ ìš©í•œ íŠ¹ì„±ë“¤ì„ ì¶”ì¶œ**í•©ë‹ˆë‹¤. ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ë‹¨ê³„ì…ë‹ˆë‹¤:\n",
    "\n",
    "**ê¸°ë³¸ íŠ¹ì„±:**\n",
    "- `year, month, day`: ì—°, ì›”, ì¼\n",
    "- `dayofweek`: ìš”ì¼ (0=ì›”, 6=ì¼) â†’ ìš”ì¼ë³„ íŒ¨í„´ í•™ìŠµ\n",
    "- `quarter`: ë¶„ê¸° â†’ ê³„ì ˆì„± í•™ìŠµ\n",
    "- `week`: ì£¼ ë²ˆí˜¸ â†’ ì£¼ê°„ íŒ¨í„´\n",
    "- `is_month_start/end, is_quarter_start/end`: íŠ¹ì • ì‹œì  (íŒë§¤ ê¸‰ì¦ ì‹œê¸°)\n",
    "\n",
    "**Cyclical íŠ¹ì„± (ì¤‘ìš”!):**\n",
    "- `month_sin/cos`: 12ì›”(11)ê³¼ 1ì›”(0)ì´ ì‹¤ì œë¡œëŠ” ì¸ì ‘í•˜ë¯€ë¡œ sin/cosë¡œ ë³€í™˜\n",
    "- `dayofweek_sin/cos`: ê¸ˆìš”ì¼ê³¼ í† ìš”ì¼ì´ ìˆ˜ì¹˜ì ìœ¼ë¡œ ê°€ê¹Œì›Œì•¼ í•¨\n",
    "- ì´ë ‡ê²Œ í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ì´ 12ì›”ê³¼ 1ì›”ì˜ ê´€ê³„ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•™ìŠµí•˜ì§€ ëª»í•¨\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 18ê°œ â†’ 26ê°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5db104",
   "metadata": {},
   "source": [
    "## 5. Stores ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c1ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after merge: (3000888, 24)\n",
      "Store ë³‘í•© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Store ì •ë³´ë¥¼ Train, Testì— ë³‘í•©\n",
    "train = train.merge(stores, on='store_nbr', how='left')\n",
    "test = test.merge(stores, on='store_nbr', how='left')\n",
    "\n",
    "print(f\"Train shape after merge: {train.shape}\")\n",
    "print(\"Store ë³‘í•© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74f69d",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ë§¤ì¥ ì •ë³´(type, cluster ë“±)ë¥¼ train/testì— ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- `store_nbr`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge â†’ ê° í–‰ì— í•´ë‹¹ ë§¤ì¥ì˜ íŠ¹ì„±ì´ ì¶”ê°€ë¨\n",
    "- ë‹¤ë¥¸ ë§¤ì¥ì€ ë‹¤ë¥¸ íŒë§¤ íŒ¨í„´ì„ ê°€ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ **ë§¤ì¥ë³„ íŠ¹ì„±ì´ ì¤‘ìš”**\n",
    "- ì˜ˆ: ìŠˆí¼ë§ˆì¼“(type=A)ì€ í¸ì˜ì (type=D)ê³¼ íŒë§¤ íŒ¨í„´ì´ ë‹¤ë¦„\n",
    "\n",
    "**ê²°ê³¼:** ë§¤ì¥ ì •ë³´ 6ê°œ ì»¬ëŸ¼ ì¶”ê°€ (type, cluster, city, state, location_type ë“±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a453ca",
   "metadata": {},
   "source": [
    "## 6. Oil ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ba498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²˜ë¦¬ í›„ Train ê²°ì¸¡ì¹˜: 0\n",
      "ì²˜ë¦¬ í›„ Test ê²°ì¸¡ì¹˜: 0\n"
     ]
    }
   ],
   "source": [
    "# Oil ê°€ê²© ì •ë³´ ë³‘í•©\n",
    "oil_renamed = oil.rename(columns={'dcoilwtico': 'oil_price'})\n",
    "\n",
    "train = train.merge(oil_renamed, on='date', how='left')\n",
    "test = test.merge(oil_renamed, on='date', how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì„ í˜• ë³´ê°„\n",
    "train['oil_price'] = train['oil_price'].interpolate(method='linear')\n",
    "test['oil_price'] = test['oil_price'].interpolate(method='linear')\n",
    "\n",
    "# ì—¬ì „íˆ ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "train['oil_price'].fillna(train['oil_price'].mean(), inplace=True)\n",
    "test['oil_price'].fillna(test['oil_price'].mean(), inplace=True)\n",
    "\n",
    "print(f\"ì²˜ë¦¬ í›„ Train ê²°ì¸¡ì¹˜: {train['oil_price'].isnull().sum()}\")\n",
    "print(f\"ì²˜ë¦¬ í›„ Test ê²°ì¸¡ì¹˜: {test['oil_price'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11df0b",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ìœ ê°€ ë°ì´í„°ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- ê²½ì œ ì§€í‘œë¡œì„œ ìœ ê°€ëŠ” ì†Œë¹„ íŒ¨í„´ì— ì˜í–¥ì„ ë¯¸ì¹¨\n",
    "- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬ 3ë‹¨ê³„:**\n",
    "  1. `interpolate()`: ì„ í˜• ë³´ê°„ (ê°€ì¥ ì¼ë°˜ì , ì—°ì†ì„± ìœ ì§€)\n",
    "  2. ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (edge case ì²˜ë¦¬)\n",
    "  \n",
    "**ì™œ ì„ í˜• ë³´ê°„?** ìœ ê°€ëŠ” ê¸‰ê²©í•œ ë³€ë™ì´ ì•„ë‹Œ ì—°ì†ì ìœ¼ë¡œ ë³€í•˜ëŠ” ê²½ì œ ì§€í‘œì´ê¸° ë•Œë¬¸\n",
    "\n",
    "**ê²°ê³¼:** oil_price ì»¬ëŸ¼ ì¶”ê°€ (ê²°ì¸¡ì¹˜ 0ê°œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37966b6b",
   "metadata": {},
   "source": [
    "## 7. Holidays/Events ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fc387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train íœ´ì¼ ë¹„ìœ¨: 8.71%\n",
      "Test íœ´ì¼ ë¹„ìœ¨: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# íœ´ì¼ ì •ë³´\n",
    "holidays_national = holidays[holidays['locale'] == 'National'][['date', 'type']].copy()\n",
    "holidays_national.rename(columns={'type': 'holiday_type'}, inplace=True)\n",
    "holidays_national['is_holiday'] = 1\n",
    "\n",
    "# Train, Testì— êµ­ê°€ íœ´ì¼ ì •ë³´ ë³‘í•©\n",
    "train = train.merge(holidays_national[['date', 'is_holiday']], on='date', how='left')\n",
    "test = test.merge(holidays_national[['date', 'is_holiday']], on='date', how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ëŠ” 0 (íœ´ì¼ ì•„ë‹˜)\n",
    "train['is_holiday'].fillna(0, inplace=True)\n",
    "test['is_holiday'].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Train íœ´ì¼ ë¹„ìœ¨: {train['is_holiday'].sum() / len(train) * 100:.2f}%\")\n",
    "print(f\"Test íœ´ì¼ ë¹„ìœ¨: {test['is_holiday'].sum() / len(test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95108ea8",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**íœ´ì¼/ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- êµ­ê°€ íœ´ì¼(National) ë˜ëŠ” ì§€ì—­ íœ´ì¼(Regional) ì •ë³´\n",
    "- **íœ´ì¼ì€ íŒë§¤ì— í° ì˜í–¥**: ë³´í†µ íœ´ì¼ì€ íŒë§¤ ì¦ê°€\n",
    "- **ì „ì²˜ë¦¬ ë°©ì‹:** êµ­ê°€ íœ´ì¼ë§Œ ì‚¬ìš© (ë” ì¼ê´€ì„± ìˆìŒ)\n",
    "- ê²°ì¸¡ì¹˜ = 0 (íœ´ì¼ì´ ì•„ë‹˜)\n",
    "\n",
    "**Binary feature:** is_holiday âˆˆ {0, 1}\n",
    "- ì´ë ‡ê²Œ ë‹¨ìˆœí•˜ê²Œ í•´ì•¼ ëª¨ë¸ì´ ì‰½ê²Œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fa37a",
   "metadata": {},
   "source": [
    "## 8. Transactions ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f303a1",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ì¼ì¼ ê±°ë˜ ê±´ìˆ˜(transactions) ì •ë³´ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- `store_nbr`ì™€ `date` ëª¨ë‘ë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge (í•œ ë§¤ì¥ í•œ ë‚ ì˜ ê±°ë˜ ê±´ìˆ˜)\n",
    "- **ê±°ë˜ ê±´ìˆ˜ëŠ” íŒë§¤ëŸ‰ê³¼ ê°•í•œ ìƒê´€ê´€ê³„**: ì†ë‹˜ì´ ë§ìœ¼ë©´ íŒë§¤ë„ ë§ìŒ\n",
    "- **ê°•ë ¥í•œ ì˜ˆì¸¡ íŠ¹ì„±**\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ ì²˜ë¦¬:**\n",
    "- ê° ë§¤ì¥ë³„ í‰ê·  ê±°ë˜ëŸ‰ìœ¼ë¡œ ì±„ìš°ê¸° (ë§¤ì¥ë§ˆë‹¤ ê±°ë˜ëŸ‰ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ)\n",
    "- ë” ì •êµí•œ ì ‘ê·¼: store_nbrë³„ë¡œ ë”°ë¡œ ê³„ì‚°\n",
    "\n",
    "**ê²°ê³¼:** n_transactions ì»¬ëŸ¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b008b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ê±°ë˜ëŸ‰ ê²°ì¸¡ì¹˜: 0\n",
      "Test ê±°ë˜ëŸ‰ ê²°ì¸¡ì¹˜: 0\n"
     ]
    }
   ],
   "source": [
    "# ê±°ë˜ëŸ‰ ì •ë³´ ë³‘í•©\n",
    "transactions_renamed = transactions.rename(columns={'transactions': 'n_transactions'})\n",
    "\n",
    "train = train.merge(transactions_renamed, on=['date', 'store_nbr'], how='left')\n",
    "test = test.merge(transactions_renamed, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ê° ê°€ê²Œë³„ í‰ê·  ê±°ë˜ëŸ‰ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "store_avg_transactions = train.groupby('store_nbr')['n_transactions'].mean()\n",
    "train['n_transactions'].fillna(train['store_nbr'].map(store_avg_transactions), inplace=True)\n",
    "test['n_transactions'].fillna(test['store_nbr'].map(store_avg_transactions), inplace=True)\n",
    "\n",
    "print(f\"Train ê±°ë˜ëŸ‰ ê²°ì¸¡ì¹˜: {train['n_transactions'].isnull().sum()}\")\n",
    "print(f\"Test ê±°ë˜ëŸ‰ ê²°ì¸¡ì¹˜: {test['n_transactions'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e5dd9",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**Lag features (ì§€ì—° íŠ¹ì„±)ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤. ì´ê²ƒì€ **ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ íŠ¹ì„±**ì…ë‹ˆë‹¤:\n",
    "\n",
    "**ê°œë…:**\n",
    "- `sales_lag_1`: ì–´ì œì˜ íŒë§¤ëŸ‰ â†’ ì–´ì œê°€ ë§ìœ¼ë©´ ì˜¤ëŠ˜ë„ ë§ì„ ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "- `sales_lag_7`: 1ì£¼ì¼ ì „ íŒë§¤ëŸ‰ â†’ ì£¼ê°„ íŒ¨í„´ í•™ìŠµ\n",
    "- `sales_lag_14`: 2ì£¼ ì „ íŒë§¤ëŸ‰ â†’ ê²©ì£¼ íŒ¨í„´\n",
    "- `sales_lag_30`: 30ì¼ ì „ íŒë§¤ëŸ‰ â†’ ì›”ê°„ íŒ¨í„´\n",
    "\n",
    "**ì¤‘ìš”:** `groupby('store_nbr')`ë¡œ **ê° ë§¤ì¥ë³„ë¡œ ë”°ë¡œ ê³„ì‚°**\n",
    "- ë§¤ì¥ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ shift í•´ì•¼ ì‹œê°„ ìˆœì„œê°€ ì„ì´ì§€ ì•ŠìŒ\n",
    "\n",
    "**ê±°ë˜ëŸ‰ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬** (n_transactions_lag_1 ë“±)\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 8ê°œ (sales/n_transactions Ã— 4ê°œ lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9664ee",
   "metadata": {},
   "source": [
    "## 9. Lag íŠ¹ì„± ì¶”ì¶œ (ì‹œê³„ì—´ ì´ì „ ë°ì´í„°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d61bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag features ìƒì„± ì¤‘...\n",
      "âœ“ Lag features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, target_col='sales', lags=[1, 7, 14, 30]):\n",
    "    \"\"\"Lag features ìƒì„±: ì´ì „ ë‚ ì§œë“¤ì˜ íŒë§¤ëŸ‰\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df.groupby('store_nbr')[target_col].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Trainì— Lag features ì¶”ê°€\n",
    "print(\"Lag features ìƒì„± ì¤‘...\")\n",
    "train = create_lag_features(train, target_col='sales', lags=[1, 7, 14, 30])\n",
    "train = create_lag_features(train, target_col='n_transactions', lags=[1, 7, 14, 30])\n",
    "\n",
    "print(\"âœ“ Lag features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43bc07",
   "metadata": {},
   "source": [
    "## 10. Rolling íŠ¹ì„± ì¶”ì¶œ (ì´ë™ í‰ê·  ë° í‘œì¤€í¸ì°¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd742872",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**Rolling features (ì´ë™í†µê³„)ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤. ì´ê²ƒë„ ë§¤ìš° ì¤‘ìš”í•œ íŠ¹ì„±ì…ë‹ˆë‹¤:\n",
    "\n",
    "**ê° window(7ì¼, 14ì¼, 30ì¼)ë§ˆë‹¤ 4ê°€ì§€ í†µê³„:**\n",
    "- `roll_mean`: ì´ë™í‰ê·  â†’ ì¶”ì„¸(trend) ìº¡ì²˜\n",
    "- `roll_std`: ì´ë™ í‘œì¤€í¸ì°¨ â†’ ë³€ë™ì„±(volatility) \n",
    "- `roll_min`: ìµœì†Ÿê°’ â†’ ìµœì € íŒë§¤ëŸ‰\n",
    "- `roll_max`: ìµœëŒ“ê°’ â†’ ìµœê³  íŒë§¤ëŸ‰\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "```\n",
    "sales_roll_mean_7 = ì§€ë‚œ 7ì¼ê°„ì˜ í‰ê·  íŒë§¤ëŸ‰\n",
    "sales_roll_std_7 = ì§€ë‚œ 7ì¼ê°„ì˜ íŒë§¤ëŸ‰ ë³€ë™ì„±\n",
    "```\n",
    "\n",
    "**min_periods=1:** ì²˜ìŒ ëª‡ í–‰ë„ ê³„ì‚° ê°€ëŠ¥ (ì²˜ìŒ 1ì¼ì€ 1ì¼ í‰ê· )\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 24ê°œ (sales/n_transactions Ã— 3ê°œ windows Ã— 4ê°€ì§€ í†µê³„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f474b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling features ìƒì„± ì¤‘...\n",
      "âœ“ Rolling features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_rolling_features(df, target_col='sales', windows=[7, 14, 30]):\n",
    "    \"\"\"Rolling statistics ìƒì„±: ì´ë™í‰ê· , í‘œì¤€í¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    for window in windows:\n",
    "        df[f'{target_col}_roll_mean_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'{target_col}_roll_std_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "        df[f'{target_col}_roll_min_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).min()\n",
    "        )\n",
    "        df[f'{target_col}_roll_max_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).max()\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Trainì— Rolling features ì¶”ê°€\n",
    "print(\"Rolling features ìƒì„± ì¤‘...\")\n",
    "train = create_rolling_features(train, target_col='sales', windows=[7, 14, 30])\n",
    "train = create_rolling_features(train, target_col='n_transactions', windows=[7, 14, 30])\n",
    "\n",
    "print(\"âœ“ Rolling features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24ffd7",
   "metadata": {},
   "source": [
    "## 11. Year-over-Year íŠ¹ì„± (ì‘ë…„ ê°™ì€ ë‚ ì§œì˜ íŒë§¤ëŸ‰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3c9fe",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**Year-over-Year (YoY) íŠ¹ì„±ì„ ìƒì„±**í•©ë‹ˆë‹¤. **ê³„ì ˆì„±(seasonality) ìº¡ì²˜**:\n",
    "\n",
    "**ê°œë…:**\n",
    "- `sales_yoy_365`: 365ì¼ ì „(ì‘ë…„ ê°™ì€ ë‚ )ì˜ íŒë§¤ëŸ‰\n",
    "- ì‘ë…„ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ê°€ ë§ì´ íŒ”ë ¸ë‹¤ë©´, ì˜¬í•´ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë„ ë§ì´ íŒ”ë¦´ ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "- **ì—°ê°„ ê³„ì ˆ íŒ¨í„´**ì„ ëª¨ë¸ì— ì•Œë ¤ì¤Œ\n",
    "\n",
    "**ì¥ì :**\n",
    "- ë°ì´í„°ê°€ 3ë…„ (2013~2015)ì´ë¯€ë¡œ 365ì¼ ì „ ë°ì´í„°ê°€ ì¶©ë¶„íˆ ì¡´ì¬\n",
    "- íœ´ì¼, í”„ë¡œëª¨ì…˜ ê°™ì€ ì£¼ê¸°ì  ì´ë²¤íŠ¸ ìº¡ì²˜\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 2ê°œ (sales_yoy_365, n_transactions_yoy_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6e280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-over-Year features ìƒì„± ì¤‘...\n",
      "âœ“ YoY features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_yoy_features(df, target_col='sales'):\n",
    "    \"\"\"Year-over-Year íŠ¹ì„±: 365ì¼ ì „ íŒë§¤ëŸ‰ (ê°™ì€ ê³„ì ˆ)\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    df[f'{target_col}_yoy_365'] = df.groupby('store_nbr')[target_col].shift(365)\n",
    "    return df\n",
    "\n",
    "# Trainì— YoY features ì¶”ê°€\n",
    "print(\"Year-over-Year features ìƒì„± ì¤‘...\")\n",
    "train = create_yoy_features(train, target_col='sales')\n",
    "train = create_yoy_features(train, target_col='n_transactions')\n",
    "\n",
    "print(\"âœ“ YoY features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7fd11",
   "metadata": {},
   "source": [
    "## 12. Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7df347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì¤‘...\n",
      "âœ“ Test ë°ì´í„° ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ\n",
      "\n",
      "ì¶”ê°€ëœ ì´ 34ê°œ íŠ¹ì„±ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...\n",
      "âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Test ë°ì´í„°ì—ë„ ê°™ì€ íŠ¹ì„±ë“¤ì„ ì¶”ê°€í•˜ë˜, Trainê³¼ì˜ ì—°ì†ì„± ë³´ì¥\n",
    "print(\"Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì¤‘...\")\n",
    "\n",
    "# Trainê³¼ Testë¥¼ ë³‘í•©í•´ì„œ lag ê³„ì‚°\n",
    "train_test_combined = pd.concat(\n",
    "    [train[['store_nbr', 'date', 'sales', 'n_transactions']], \n",
    "     test[['store_nbr', 'date', 'n_transactions']]], \n",
    "    axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "# ë³‘í•© ë°ì´í„°ì—ì„œ Lag/Rolling/YoY íŠ¹ì„± ìƒì„±\n",
    "train_test_combined = create_lag_features(train_test_combined, target_col='sales', lags=[1, 7, 14, 30])\n",
    "train_test_combined = create_lag_features(train_test_combined, target_col='n_transactions', lags=[1, 7, 14, 30])\n",
    "train_test_combined = create_rolling_features(train_test_combined, target_col='sales', windows=[7, 14, 30])\n",
    "train_test_combined = create_rolling_features(train_test_combined, target_col='n_transactions', windows=[7, 14, 30])\n",
    "train_test_combined = create_yoy_features(train_test_combined, target_col='sales')\n",
    "train_test_combined = create_yoy_features(train_test_combined, target_col='n_transactions')\n",
    "\n",
    "# Test ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "test_lag_features = train_test_combined[train_test_combined.index >= len(train)].copy()\n",
    "test_lag_features = test_lag_features.drop(columns=['sales', 'n_transactions'], errors='ignore')\n",
    "\n",
    "# Testì— íŠ¹ì„± ì¶”ê°€\n",
    "for col in test_lag_features.columns:\n",
    "    if col not in test.columns and col != 'date' and col != 'store_nbr':\n",
    "        test[col] = test_lag_features[col].values\n",
    "\n",
    "print(\"âœ“ Test ë°ì´í„° ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "lag_cols = [col for col in train.columns if 'lag' in col or 'roll' in col or 'yoy' in col]\n",
    "print(f\"\\nì¶”ê°€ëœ ì´ {len(lag_cols)}ê°œ íŠ¹ì„±ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "for col in lag_cols:\n",
    "    if col in train.columns:\n",
    "        fill_value = train.groupby('store_nbr')[col].transform('mean')\n",
    "        train[col].fillna(fill_value, inplace=True)\n",
    "        train[col].fillna(train[col].mean(), inplace=True)\n",
    "    \n",
    "    if col in test.columns:\n",
    "        fill_value = test.groupby('store_nbr')[col].transform('mean')\n",
    "        test[col].fillna(fill_value, inplace=True)\n",
    "        test[col].fillna(test[col].mean(), inplace=True)\n",
    "\n",
    "print(\"âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387f690",
   "metadata": {},
   "source": [
    "## 13. Categorical íŠ¹ì„± ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd23b6",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„±ì„ ì¶”ê°€**í•©ë‹ˆë‹¤. ì´ê²ƒì´ ì¤‘ìš”í•œ ì´ìœ :\n",
    "\n",
    "**ë¬¸ì œ:** Test ë°ì´í„°ì˜ lagë¥¼ ê³„ì‚°í•˜ë ¤ë©´ Trainì˜ ë§ˆì§€ë§‰ ë°ì´í„°ê°€ í•„ìš”\n",
    "- `test_lag_1` = testì˜ ì–´ì œ íŒë§¤ëŸ‰ì¸ë°, ê·¸ ì–´ì œëŠ” Trainì˜ ë§ˆì§€ë§‰ ë‚ ì¼ ìˆ˜ ìˆìŒ\n",
    "- Testë§Œìœ¼ë¡œëŠ” ê³„ì‚° ë¶ˆê°€ëŠ¥!\n",
    "\n",
    "**í•´ê²°ë²•:**\n",
    "1. Train + Testë¥¼ **ì‹œê°„ìˆœìœ¼ë¡œ ì—°ê²°**\n",
    "2. ì´ ë³‘í•© ë°ì´í„°ì—ì„œ lag/rolling/yoy íŠ¹ì„± ê³„ì‚°\n",
    "3. Test ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ì›ë˜ Test ë°ì´í„°ì— ë³‘í•©\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ ì²˜ë¦¬:**\n",
    "- ì²˜ìŒ ëª‡ í–‰ì˜ lagê°’ì€ `groupby('store_nbr').transform('mean')` ì‚¬ìš©\n",
    "- ê° ë§¤ì¥ë³„ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (ì „ì²´ í‰ê· ë³´ë‹¤ ì •í™•í•¨)\n",
    "\n",
    "**ê²°ê³¼:** Testë„ Trainê³¼ ë™ì¼í•œ íŠ¹ì„± ê°œìˆ˜ë¥¼ ê°€ì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4208ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¹´í…Œê³ ë¦¬ ê°’ ê°œìˆ˜:\n",
      "type: 5\n",
      "family: 33\n",
      "\n",
      "Train shape: (3008016, 97)\n",
      "Test shape: (28512, 96)\n"
     ]
    }
   ],
   "source": [
    "# ì¹´í…Œê³ ë¦¬ íŠ¹ì„± í™•ì¸\n",
    "categorical_cols = ['type', 'family']\n",
    "\n",
    "print(\"ì¹´í…Œê³ ë¦¬ ê°’ ê°œìˆ˜:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {train[col].nunique()}\")\n",
    "\n",
    "# One-hot encoding\n",
    "train = pd.get_dummies(train, columns=categorical_cols, drop_first=False)\n",
    "test = pd.get_dummies(test, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Trainê³¼ Testì˜ ì»¬ëŸ¼ ë§ì¶”ê¸°\n",
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "\n",
    "for col in test_cols - train_cols:\n",
    "    test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "for col in train_cols - test_cols:\n",
    "    test[col] = 0\n",
    "\n",
    "test = test[train.columns.drop('sales', errors='ignore')]\n",
    "\n",
    "print(f\"\\nTrain shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529da478",
   "metadata": {},
   "source": [
    "## 14. ê²°ì¸¡ì¹˜ ìµœì¢… í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be7f64",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ë²”ì£¼í˜•(Categorical) íŠ¹ì„±ì„ ì¸ì½”ë”©**í•©ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìë§Œ ì´í•´í•˜ê¸° ë•Œë¬¸:\n",
    "\n",
    "**ë²”ì£¼í˜• íŠ¹ì„±:**\n",
    "- `type`: ë§¤ì¥ ìœ í˜• (A, B, C, D) â†’ 4ê°œ ê°’\n",
    "- `family`: ìƒí’ˆ ë¶„ë¥˜ (33ê°œ ê°’: Beverages, Dairy, Frozen Food ë“±)\n",
    "\n",
    "**One-hot encoding:**\n",
    "```python\n",
    "type_A=1, type_B=0, type_C=0, type_D=0  # type='A'ì¸ ê²½ìš°\n",
    "family_Beverages=1, family_Dairy=0, ...  # family='Beverages'ì¸ ê²½ìš°\n",
    "```\n",
    "\n",
    "**Trainê³¼ Test ì»¬ëŸ¼ ë§ì¶”ê¸°:**\n",
    "- Testì—ë§Œ ìˆëŠ” ì¹´í…Œê³ ë¦¬ ì œê±° (Trainê³¼ ê°™ì€ ë²”ì£¼ë§Œ ìœ ì§€)\n",
    "- Trainì—ë§Œ ìˆëŠ” ì¹´í…Œê³ ë¦¬ëŠ” Testì— 0ìœ¼ë¡œ ì¶”ê°€ (ëª¨ë‘ False)\n",
    "- ì»¬ëŸ¼ ìˆœì„œë¥¼ ë™ì¼í•˜ê²Œ ì •ë ¬\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜:** 4ê°œ(type) + 33ê°œ(family) = 37ê°œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35991e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train ê²°ì¸¡ì¹˜ ===\n",
      "Series([], dtype: int64)\n",
      "\n",
      "=== Test ê²°ì¸¡ì¹˜ ===\n",
      "Series([], dtype: int64)\n",
      "\n",
      "âœ“ Trainì— ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "âœ“ Testì— ê²°ì¸¡ì¹˜ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Train ê²°ì¸¡ì¹˜ ===\")\n",
    "missing_train = train.isnull().sum()\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\n=== Test ê²°ì¸¡ì¹˜ ===\")\n",
    "missing_test = test.isnull().sum()\n",
    "print(missing_test[missing_test > 0])\n",
    "\n",
    "if missing_train.sum() == 0:\n",
    "    print(\"\\nâœ“ Trainì— ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "if missing_test.sum() == 0:\n",
    "    print(\"âœ“ Testì— ê²°ì¸¡ì¹˜ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e233e0",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ê²°ì¸¡ì¹˜(Missing values)ë¥¼ ìµœì¢… í™•ì¸**í•©ë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ì „ í•„ìˆ˜ ê²€ì‚¬:\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ìˆìœ¼ë©´:**\n",
    "- XGBoost ë“± ì¼ë¶€ ëª¨ë¸: ìë™ ì²˜ë¦¬ (ì„±ëŠ¥ ì €í•˜)\n",
    "- ë‹¤ë¥¸ ëª¨ë¸ë“¤: ì—ëŸ¬ ë°œìƒ\n",
    "\n",
    "**í™•ì¸ í•­ëª©:**\n",
    "1. Trainì˜ ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜\n",
    "2. Testì˜ ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜\n",
    "3. ê²°ì¸¡ì¹˜ê°€ ìˆìœ¼ë©´ ì–´ë””ì„œ ì™”ëŠ”ì§€ ì¶”ì \n",
    "\n",
    "**ì´ìƒì ì¸ ìƒíƒœ:** ëª¨ë“  ê²°ì¸¡ì¹˜ = 0\n",
    "- ì•ì„œ interpolate, fillnaë¡œ ì²˜ë¦¬í–ˆê¸° ë•Œë¬¸ì— 0ì´ì–´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678eaca",
   "metadata": {},
   "source": [
    "## 15. ë°ì´í„° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d08392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train ë°ì´í„° ì •ë³´ ===\n",
      "Shape: (3008016, 97)\n",
      "ì»¬ëŸ¼ ìˆ˜: 97\n",
      "\n",
      "ìˆ˜ì¹˜í˜• íŠ¹ì„± í†µê³„:\n",
      "                 id                           date     store_nbr  \\\n",
      "count  3.008016e+06                        3008016  3.008016e+06   \n",
      "mean   1.501508e+06  2015-04-24 22:50:02.843602688  2.750000e+01   \n",
      "min    0.000000e+00            2013-01-01 00:00:00  1.000000e+00   \n",
      "25%    7.520038e+05            2014-02-27 18:00:00  1.400000e+01   \n",
      "50%    1.502226e+06            2015-04-25 12:00:00  2.750000e+01   \n",
      "75%    2.248883e+06            2016-06-18 06:00:00  4.100000e+01   \n",
      "max    3.000887e+06            2017-08-15 00:00:00  5.400000e+01   \n",
      "std    8.657303e+05                            NaN  1.558579e+01   \n",
      "\n",
      "              sales   onpromotion          year         month           day  \\\n",
      "count  3.008016e+06  3.008016e+06  3.008016e+06  3.008016e+06  3.008016e+06   \n",
      "mean   3.582691e+02  2.609620e+00  2.014839e+03  6.209123e+00  1.561789e+01   \n",
      "min    0.000000e+00  0.000000e+00  2.013000e+03  1.000000e+00  1.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  2.014000e+03  3.000000e+00  8.000000e+00   \n",
      "50%    1.100000e+01  0.000000e+00  2.015000e+03  6.000000e+00  1.600000e+01   \n",
      "75%    1.960000e+02  0.000000e+00  2.016000e+03  9.000000e+00  2.300000e+01   \n",
      "max    1.247170e+05  7.410000e+02  2.017000e+03  1.200000e+01  3.100000e+01   \n",
      "std    1.103511e+03  1.226308e+01  1.344969e+00  3.384974e+00  8.799659e+00   \n",
      "\n",
      "            quarter     dayofweek  ...  n_transactions_roll_mean_14  \\\n",
      "count  3.008016e+06  3.008016e+06  ...                 3.008016e+06   \n",
      "mean   2.410545e+00  3.002370e+00  ...                 1.672260e+03   \n",
      "min    1.000000e+00  0.000000e+00  ...                 5.000000e+00   \n",
      "25%    1.000000e+00  1.000000e+00  ...                 1.053286e+03   \n",
      "50%    2.000000e+00  3.000000e+00  ...                 1.375529e+03   \n",
      "75%    3.000000e+00  5.000000e+00  ...                 2.073000e+03   \n",
      "max    4.000000e+00  6.000000e+00  ...                 8.359000e+03   \n",
      "std    1.099465e+00  2.001775e+00  ...                 9.378308e+02   \n",
      "\n",
      "       n_transactions_roll_std_14  n_transactions_roll_min_14  \\\n",
      "count                3.008016e+06                3.008016e+06   \n",
      "mean                 3.446347e+01                1.632191e+03   \n",
      "min                  0.000000e+00                5.000000e+00   \n",
      "25%                  0.000000e+00                1.021000e+03   \n",
      "50%                  0.000000e+00                1.341000e+03   \n",
      "75%                  3.033195e+01                2.029000e+03   \n",
      "max                  1.934364e+03                8.359000e+03   \n",
      "std                  8.526980e+01                9.161017e+02   \n",
      "\n",
      "       n_transactions_roll_max_14  n_transactions_roll_mean_30  \\\n",
      "count                3.008016e+06                 3.008016e+06   \n",
      "mean                 1.712330e+03                 1.672270e+03   \n",
      "min                  5.000000e+00                 5.000000e+00   \n",
      "25%                  1.081000e+03                 1.057800e+03   \n",
      "50%                  1.409000e+03                 1.376500e+03   \n",
      "75%                  2.122000e+03                 2.070200e+03   \n",
      "max                  8.359000e+03                 8.359000e+03   \n",
      "std                  9.655612e+02                 9.330048e+02   \n",
      "\n",
      "       n_transactions_roll_std_30  n_transactions_roll_min_30  \\\n",
      "count                3.008016e+06                3.008016e+06   \n",
      "mean                 7.339199e+01                1.582884e+03   \n",
      "min                  0.000000e+00                5.000000e+00   \n",
      "25%                  6.048083e+00                9.980000e+02   \n",
      "50%                  3.633226e+01                1.304000e+03   \n",
      "75%                  9.172926e+01                1.966000e+03   \n",
      "max                  1.895866e+03                8.359000e+03   \n",
      "std                  1.099770e+02                8.806837e+02   \n",
      "\n",
      "       n_transactions_roll_max_30  sales_yoy_365  n_transactions_yoy_365  \n",
      "count                3.008016e+06   3.008016e+06            3.008016e+06  \n",
      "mean                 1.761655e+03   3.576441e+02            1.672468e+03  \n",
      "min                  5.000000e+00   0.000000e+00            5.000000e+00  \n",
      "25%                  1.116180e+03   0.000000e+00            1.050000e+03  \n",
      "50%                  1.453000e+03   1.100000e+01            1.375000e+03  \n",
      "75%                  2.178000e+03   2.009140e+02            2.075000e+03  \n",
      "max                  8.359000e+03   1.247170e+05            8.359000e+03  \n",
      "std                  9.915692e+02   1.099230e+03            9.417604e+02  \n",
      "\n",
      "[8 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Train ë°ì´í„° ì •ë³´ ===\")\n",
    "print(f\"Shape: {train.shape}\")\n",
    "print(f\"ì»¬ëŸ¼ ìˆ˜: {len(train.columns)}\")\n",
    "print(f\"\\nìˆ˜ì¹˜í˜• íŠ¹ì„± í†µê³„:\")\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefac0c",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ë°ì´í„°ì˜ í†µê³„ ì •ë³´ë¥¼ ì¶œë ¥**í•©ë‹ˆë‹¤. ë°ì´í„° ë¶„í¬ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”:\n",
    "\n",
    "**í™•ì¸ í•­ëª©:**\n",
    "- `count`: ë¹„ê²°ì¸¡ì¹˜ ê°œìˆ˜ (ëŒ€ë¶€ë¶„ ê°™ì•„ì•¼ í•¨)\n",
    "- `mean`: í‰ê·  íŒë§¤ëŸ‰ (ìŠ¤ì¼€ì¼ ê°ì¡ê¸°)\n",
    "- `std`: í‘œì¤€í¸ì°¨ (íŒë§¤ëŸ‰ ë³€ë™ì„±)\n",
    "- `min/max`: ìµœì†Œ/ìµœëŒ€ê°’ (ì´ìƒì¹˜ í™•ì¸)\n",
    "- `25%, 50%, 75%`: ì‚¬ë¶„ìœ„ìˆ˜ (ë¶„í¬ ëª¨ì–‘)\n",
    "\n",
    "**ì´ìƒì¹˜ ì—¬ë¶€ í™•ì¸:**\n",
    "- minì´ 0ì´ìƒ? â†’ íŒë§¤ëŸ‰ì´ ìŒìˆ˜ì¼ ìˆ˜ ì—†ìŒ âœ“\n",
    "- maxê°€ ë„ˆë¬´ í¬ì§€ëŠ” ì•Šì€ê°€? â†’ í”„ë¡œëª¨ì…˜ì´ë‚˜ í° ë§¤ì¥ì¼ ìˆ˜ ìˆìŒ\n",
    "\n",
    "**ìŠ¤ì¼€ì¼ë§ í•„ìš”?** \n",
    "- ì´í›„ ëª¨ë¸ í›ˆë ¨ ì‹œ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸(XGBoost)ì€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”\n",
    "- ì‹ ê²½ë§ ë“±ì€ í•„ìš”í•  ìˆ˜ ìˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1db5f7",
   "metadata": {},
   "source": [
    "## 16. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe2df86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ train_processed.csv ì €ì¥ ì™„ë£Œ\n",
      "âœ“ test_processed.csv ì €ì¥ ì™„ë£Œ\n",
      "\n",
      "ì´ 3008016 í–‰ì˜ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n",
      "ì´ 28512 í–‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥\n",
    "train.to_csv('train_processed.csv', index=False)\n",
    "test.to_csv('test_processed.csv', index=False)\n",
    "\n",
    "print(\"âœ“ train_processed.csv ì €ì¥ ì™„ë£Œ\")\n",
    "print(\"âœ“ test_processed.csv ì €ì¥ ì™„ë£Œ\")\n",
    "print(f\"\\nì´ {len(train)} í–‰ì˜ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ì´ {len(test)} í–‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c325f",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥**í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„(ëª¨ë¸ í›ˆë ¨)ì—ì„œ ì‚¬ìš©:\n",
    "\n",
    "**ì €ì¥í•˜ëŠ” ì´ìœ :**\n",
    "1. **ì¬ì‚¬ìš©ì„±**: ëª¨ë¸ í›ˆë ¨í•  ë•Œë§ˆë‹¤ ì´ ì „ì²˜ë¦¬ ê³¼ì •ì„ ë°˜ë³µí•  í•„ìš” ì—†ìŒ\n",
    "2. **ì‹œê°„ ì ˆì•½**: ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ë°”ë¡œ ëª¨ë¸ í›ˆë ¨ ê°€ëŠ¥\n",
    "3. **ì¼ê´€ì„±**: ëª¨ë“  ë¶„ì„ì´ ë™ì¼í•œ ë°ì´í„°ì…‹ ê¸°ë°˜\n",
    "\n",
    "**ì €ì¥ë˜ëŠ” íŒŒì¼:**\n",
    "- `train_processed.csv`: í•™ìŠµ ë°ì´í„° (3,000,888 í–‰ Ã— ì•½ 90ì—´)\n",
    "- `test_processed.csv`: í…ŒìŠ¤íŠ¸ ë°ì´í„° (28,512 í–‰ Ã— ì•½ 90ì—´)\n",
    "\n",
    "**ì»¬ëŸ¼ ì •ë³´:**\n",
    "- Train: `sales` (target) í¬í•¨\n",
    "- Test: `sales` ë¯¸í¬í•¨ (ì˜ˆì¸¡í•´ì•¼ í•  ê°’)\n",
    "- ë‘˜ ë‹¤: `date`, `store_nbr` ë“± ë©”íƒ€ë°ì´í„° í¬í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa41302",
   "metadata": {},
   "source": [
    "## 17. íŠ¹ì„± ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356aec92",
   "metadata": {},
   "source": [
    "### ğŸ“š ì„¤ëª…\n",
    "\n",
    "**ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ëª¨ë“  íŠ¹ì„±ì„ ë‚˜ì—´**í•©ë‹ˆë‹¤. ëª¨ë¸ í›ˆë ¨ì˜ ì…ë ¥ íŠ¹ì„± í™•ì¸:\n",
    "\n",
    "**íŠ¹ì„± ì œì™¸ ì‚¬í•­:**\n",
    "- `sales`: ì˜ˆì¸¡ ëŒ€ìƒ (ì…ë ¥ì´ ì•„ë‹˜)\n",
    "- `date`: ì´ë¯¸ year/month/dayë¡œ ë¶„í•´ë¨\n",
    "- `id`: ê³ ìœ  ì‹ë³„ì (ì˜ˆì¸¡ ì„±ëŠ¥ê³¼ ë¬´ê´€)\n",
    "\n",
    "**íŠ¹ì„± ì¢…ë¥˜:**\n",
    "1. **ë‚ ì§œ íŠ¹ì„±**: year, month, day, dayofweek, month_sin/cos ë“± (13ê°œ)\n",
    "2. **ë§¤ì¥ íŠ¹ì„±**: store_nbr, type_A/B/C/D, cluster, city ë“± (10+ê°œ)\n",
    "3. **ê²½ì œ íŠ¹ì„±**: oil_price (1ê°œ)\n",
    "4. **íœ´ì¼**: is_holiday (1ê°œ)\n",
    "5. **ê±°ë˜ëŸ‰**: n_transactions (1ê°œ)\n",
    "6. **Lag**: sales_lag_1/7/14/30, n_transactions_lag_1/7/14/30 (8ê°œ)\n",
    "7. **Rolling**: roll_mean/std/min/max (24ê°œ)\n",
    "8. **YoY**: yoy_365 (2ê°œ)\n",
    "9. **ë²”ì£¼í˜•**: family_Beverages, ... (33ê°œ)\n",
    "\n",
    "**ì´ íŠ¹ì„± ìˆ˜: ì•½ 90~100ê°œ**\n",
    "- ì´ˆê¸° ì»¬ëŸ¼ 18ê°œ â†’ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•´ 5ë°° ì´ìƒ ì¦ê°€\n",
    "- ì´ê²ƒì´ ëª¨ë¸ ì„±ëŠ¥ì˜ í•µì‹¬!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9beb2e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì´ íŠ¹ì„± ê°œìˆ˜: 94\n",
      "\n",
      "íŠ¹ì„± ëª©ë¡:\n",
      "1. store_nbr\n",
      "2. onpromotion\n",
      "3. year\n",
      "4. month\n",
      "5. day\n",
      "6. quarter\n",
      "7. dayofweek\n",
      "8. week\n",
      "9. is_month_start\n",
      "10. is_month_end\n",
      "11. is_quarter_start\n",
      "12. is_quarter_end\n",
      "13. month_sin\n",
      "14. month_cos\n",
      "15. dayofweek_sin\n",
      "16. dayofweek_cos\n",
      "17. city\n",
      "18. state\n",
      "19. cluster\n",
      "20. oil_price\n",
      "21. is_holiday\n",
      "22. n_transactions\n",
      "23. sales_lag_1\n",
      "24. sales_lag_7\n",
      "25. sales_lag_14\n",
      "26. sales_lag_30\n",
      "27. n_transactions_lag_1\n",
      "28. n_transactions_lag_7\n",
      "29. n_transactions_lag_14\n",
      "30. n_transactions_lag_30\n",
      "31. sales_roll_mean_7\n",
      "32. sales_roll_std_7\n",
      "33. sales_roll_min_7\n",
      "34. sales_roll_max_7\n",
      "35. sales_roll_mean_14\n",
      "36. sales_roll_std_14\n",
      "37. sales_roll_min_14\n",
      "38. sales_roll_max_14\n",
      "39. sales_roll_mean_30\n",
      "40. sales_roll_std_30\n",
      "41. sales_roll_min_30\n",
      "42. sales_roll_max_30\n",
      "43. n_transactions_roll_mean_7\n",
      "44. n_transactions_roll_std_7\n",
      "45. n_transactions_roll_min_7\n",
      "46. n_transactions_roll_max_7\n",
      "47. n_transactions_roll_mean_14\n",
      "48. n_transactions_roll_std_14\n",
      "49. n_transactions_roll_min_14\n",
      "50. n_transactions_roll_max_14\n",
      "51. n_transactions_roll_mean_30\n",
      "52. n_transactions_roll_std_30\n",
      "53. n_transactions_roll_min_30\n",
      "54. n_transactions_roll_max_30\n",
      "55. sales_yoy_365\n",
      "56. n_transactions_yoy_365\n",
      "57. type_A\n",
      "58. type_B\n",
      "59. type_C\n",
      "60. type_D\n",
      "61. type_E\n",
      "62. family_AUTOMOTIVE\n",
      "63. family_BABY CARE\n",
      "64. family_BEAUTY\n",
      "65. family_BEVERAGES\n",
      "66. family_BOOKS\n",
      "67. family_BREAD/BAKERY\n",
      "68. family_CELEBRATION\n",
      "69. family_CLEANING\n",
      "70. family_DAIRY\n",
      "71. family_DELI\n",
      "72. family_EGGS\n",
      "73. family_FROZEN FOODS\n",
      "74. family_GROCERY I\n",
      "75. family_GROCERY II\n",
      "76. family_HARDWARE\n",
      "77. family_HOME AND KITCHEN I\n",
      "78. family_HOME AND KITCHEN II\n",
      "79. family_HOME APPLIANCES\n",
      "80. family_HOME CARE\n",
      "81. family_LADIESWEAR\n",
      "82. family_LAWN AND GARDEN\n",
      "83. family_LINGERIE\n",
      "84. family_LIQUOR,WINE,BEER\n",
      "85. family_MAGAZINES\n",
      "86. family_MEATS\n",
      "87. family_PERSONAL CARE\n",
      "88. family_PET SUPPLIES\n",
      "89. family_PLAYERS AND ELECTRONICS\n",
      "90. family_POULTRY\n",
      "91. family_PREPARED FOODS\n",
      "92. family_PRODUCE\n",
      "93. family_SCHOOL AND OFFICE SUPPLIES\n",
      "94. family_SEAFOOD\n"
     ]
    }
   ],
   "source": [
    "# Trainì—ì„œ target ì œì™¸í•œ íŠ¹ì„± ëª©ë¡\n",
    "feature_cols = [col for col in train.columns if col not in ['sales', 'date', 'id']]\n",
    "\n",
    "print(f\"\\nì´ íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}\")\n",
    "print(\"\\níŠ¹ì„± ëª©ë¡:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
