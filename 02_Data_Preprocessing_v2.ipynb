{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f390897",
   "metadata": {},
   "source": [
    "## 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e65a7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03677d5c",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "ì´ ì„¹ì…˜ì—ì„œëŠ” **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì„ import**í•©ë‹ˆë‹¤:\n",
    "- `pandas`: ë°ì´í„° ì¡°ìž‘ ë° ë¶„ì„\n",
    "- `numpy`: ìˆ˜ì¹˜ ê³„ì‚° (sin, cos ë“±)\n",
    "- `warnings.filterwarnings('ignore')`: ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¹€ (í•™ìŠµ ê³¼ì • ì¤‘ ë¶ˆí•„ìš”í•œ ê²½ê³  ì œê±°)\n",
    "\n",
    "ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ë“¤ì´ ì—†ìœ¼ë©´ ì´í›„ì˜ ëª¨ë“  ë°ì´í„° ì²˜ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë¯€ë¡œ **ê°€ìž¥ ë¨¼ì € ì‹¤í–‰**ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4ef8a0",
   "metadata": {},
   "source": [
    "## 2. ë°ì´í„° ë¡œë“œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eef91c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3000888, 6)\n",
      "Test shape: (28512, 5)\n",
      "\n",
      "ë°ì´í„° ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "stores = pd.read_csv('stores.csv')\n",
    "holidays = pd.read_csv('holidays_events.csv')\n",
    "oil = pd.read_csv('oil.csv')\n",
    "transactions = pd.read_csv('transactions.csv')\n",
    "\n",
    "print(f\"Train shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")\n",
    "print(\"\\në°ì´í„° ë¡œë“œ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ae6b69",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "Kaggle ê²½ìŸì˜ ëª¨ë“  **ì›ë³¸ CSV íŒŒì¼ë“¤ì„ ë¡œë“œ**í•©ë‹ˆë‹¤:\n",
    "- `train.csv`: í•™ìŠµ ë°ì´í„° (3,626,896 í–‰) - storeë³„, dateë³„ sales í¬í•¨\n",
    "- `test.csv`: ì˜ˆì¸¡í•´ì•¼ í•  ë°ì´í„° - salesê°€ ì—†ìŒ\n",
    "- `stores.csv`: ë§¤ìž¥ ì •ë³´ (type, cluster ë“±)\n",
    "- `holidays_events.csv`: íœ´ì¼/ì´ë²¤íŠ¸ ì •ë³´\n",
    "- `oil.csv`: ì¼ì¼ ìœ ê°€ ë°ì´í„°\n",
    "- `transactions.csv`: ì¼ì¼ ê±°ëž˜ ê±´ìˆ˜\n",
    "\n",
    "ê° CSVì˜ **í¬ê¸°ë¥¼ ì¶œë ¥**í•˜ì—¬ ë°ì´í„° ë¡œë“œê°€ ì •ìƒì ìœ¼ë¡œ ë˜ì—ˆëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82070bbd",
   "metadata": {},
   "source": [
    "## 3. ë‚ ì§œ íŒŒì‹±"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0358aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ê¸°ê°„: 2013-01-01 00:00:00 ~ 2017-08-15 00:00:00\n",
      "Test ê¸°ê°„: 2017-08-16 00:00:00 ~ 2017-08-31 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# ë‚ ì§œë¥¼ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜\n",
    "train['date'] = pd.to_datetime(train['date'])\n",
    "test['date'] = pd.to_datetime(test['date'])\n",
    "oil['date'] = pd.to_datetime(oil['date'])\n",
    "holidays['date'] = pd.to_datetime(holidays['date'])\n",
    "transactions['date'] = pd.to_datetime(transactions['date'])\n",
    "\n",
    "print(f\"Train ê¸°ê°„: {train['date'].min()} ~ {train['date'].max()}\")\n",
    "print(f\"Test ê¸°ê°„: {test['date'].min()} ~ {test['date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdaa10",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ë¬¸ìžì—´ë¡œ ì €ìž¥ëœ 'date' ì»¬ëŸ¼ì„ datetime í˜•ì‹ìœ¼ë¡œ ë³€í™˜**í•©ë‹ˆë‹¤:\n",
    "- `pd.to_datetime()`: ë‚ ì§œ ë¬¸ìžì—´ì„ Python datetime ê°ì²´ë¡œ ë³€í™˜\n",
    "- ì´ë ‡ê²Œ ë³€í™˜í•´ì•¼ `.dt` ì†ì„±ìœ¼ë¡œ ì—°, ì›”, ì¼, ìš”ì¼ ë“±ì„ ì¶”ì¶œí•  ìˆ˜ ìžˆìŒ\n",
    "- ì‹œê³„ì—´ ë¶„ì„ì—ì„œ **í•„ìˆ˜ì ì¸ ì „ì²˜ë¦¬ ë‹¨ê³„**\n",
    "\n",
    "ì˜ˆì‹œ: `'2013-01-01'` â†’ `Timestamp('2013-01-01 00:00:00')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf45003",
   "metadata": {},
   "source": [
    "## 4. ë‚ ì§œ ê¸°ë°˜ íŠ¹ì„± ì¶”ì¶œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20a708d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì¶”ì¶œëœ ë‚ ì§œ íŠ¹ì„±:\n",
      "        date  year  month  day  dayofweek  month_sin  month_cos\n",
      "0 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "1 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "2 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "3 2013-01-01  2013      1    1          1        0.5   0.866025\n",
      "4 2013-01-01  2013      1    1          1        0.5   0.866025\n"
     ]
    }
   ],
   "source": [
    "def extract_date_features(df):\n",
    "    \"\"\"ë‚ ì§œì—ì„œ ì—¬ëŸ¬ íŠ¹ì„± ì¶”ì¶œ\"\"\"\n",
    "    df['year'] = df['date'].dt.year\n",
    "    df['month'] = df['date'].dt.month\n",
    "    df['day'] = df['date'].dt.day\n",
    "    df['quarter'] = df['date'].dt.quarter\n",
    "    df['dayofweek'] = df['date'].dt.dayofweek  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼\n",
    "    df['week'] = df['date'].dt.isocalendar().week\n",
    "    df['is_month_start'] = df['date'].dt.is_month_start.astype(int)\n",
    "    df['is_month_end'] = df['date'].dt.is_month_end.astype(int)\n",
    "    df['is_quarter_start'] = df['date'].dt.is_quarter_start.astype(int)\n",
    "    df['is_quarter_end'] = df['date'].dt.is_quarter_end.astype(int)\n",
    "    \n",
    "    # âœ“ ì¶”ê°€: Cyclical íŠ¹ì„± (ì‚¼ê°í•¨ìˆ˜ ë³€í™˜)\n",
    "    df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "    df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "    df['dayofweek_sin'] = np.sin(2 * np.pi * df['dayofweek'] / 7)\n",
    "    df['dayofweek_cos'] = np.cos(2 * np.pi * df['dayofweek'] / 7)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Train, Testì— íŠ¹ì„± ì¶”ì¶œ\n",
    "train = extract_date_features(train)\n",
    "test = extract_date_features(test)\n",
    "\n",
    "print(\"\\nì¶”ì¶œëœ ë‚ ì§œ íŠ¹ì„±:\")\n",
    "print(train[['date', 'year', 'month', 'day', 'dayofweek', 'month_sin', 'month_cos']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c8d46d",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ë‚ ì§œì—ì„œ ìœ ìš©í•œ íŠ¹ì„±ë“¤ì„ ì¶”ì¶œ**í•©ë‹ˆë‹¤. ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ ë‹¨ê³„ìž…ë‹ˆë‹¤:\n",
    "\n",
    "**ê¸°ë³¸ íŠ¹ì„±:**\n",
    "- `year, month, day`: ì—°, ì›”, ì¼\n",
    "- `dayofweek`: ìš”ì¼ (0=ì›”, 6=ì¼) â†’ ìš”ì¼ë³„ íŒ¨í„´ í•™ìŠµ\n",
    "- `quarter`: ë¶„ê¸° â†’ ê³„ì ˆì„± í•™ìŠµ\n",
    "- `week`: ì£¼ ë²ˆí˜¸ â†’ ì£¼ê°„ íŒ¨í„´\n",
    "- `is_month_start/end, is_quarter_start/end`: íŠ¹ì • ì‹œì  (íŒë§¤ ê¸‰ì¦ ì‹œê¸°)\n",
    "\n",
    "**Cyclical íŠ¹ì„± (ì¤‘ìš”!):**\n",
    "- `month_sin/cos`: 12ì›”(11)ê³¼ 1ì›”(0)ì´ ì‹¤ì œë¡œëŠ” ì¸ì ‘í•˜ë¯€ë¡œ sin/cosë¡œ ë³€í™˜\n",
    "- `dayofweek_sin/cos`: ê¸ˆìš”ì¼ê³¼ í† ìš”ì¼ì´ ìˆ˜ì¹˜ì ìœ¼ë¡œ ê°€ê¹Œì›Œì•¼ í•¨\n",
    "- ì´ë ‡ê²Œ í•˜ì§€ ì•Šìœ¼ë©´ ëª¨ë¸ì´ 12ì›”ê³¼ 1ì›”ì˜ ê´€ê³„ë¥¼ ì˜¬ë°”ë¥´ê²Œ í•™ìŠµí•˜ì§€ ëª»í•¨\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 18ê°œ â†’ 26ê°œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5db104",
   "metadata": {},
   "source": [
    "## 5. Stores ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8c1ce5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape after merge: (3000888, 24)\n",
      "Store ë³‘í•© ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Store ì •ë³´ë¥¼ Train, Testì— ë³‘í•©\n",
    "train = train.merge(stores, on='store_nbr', how='left')\n",
    "test = test.merge(stores, on='store_nbr', how='left')\n",
    "\n",
    "print(f\"Train shape after merge: {train.shape}\")\n",
    "print(\"Store ë³‘í•© ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac74f69d",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ë§¤ìž¥ ì •ë³´(type, cluster ë“±)ë¥¼ train/testì— ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- `store_nbr`ë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge â†’ ê° í–‰ì— í•´ë‹¹ ë§¤ìž¥ì˜ íŠ¹ì„±ì´ ì¶”ê°€ë¨\n",
    "- ë‹¤ë¥¸ ë§¤ìž¥ì€ ë‹¤ë¥¸ íŒë§¤ íŒ¨í„´ì„ ê°€ì§ˆ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ **ë§¤ìž¥ë³„ íŠ¹ì„±ì´ ì¤‘ìš”**\n",
    "- ì˜ˆ: ìŠˆí¼ë§ˆì¼“(type=A)ì€ íŽ¸ì˜ì (type=D)ê³¼ íŒë§¤ íŒ¨í„´ì´ ë‹¤ë¦„\n",
    "\n",
    "**ê²°ê³¼:** ë§¤ìž¥ ì •ë³´ 6ê°œ ì»¬ëŸ¼ ì¶”ê°€ (type, cluster, city, state, location_type ë“±)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a453ca",
   "metadata": {},
   "source": [
    "## 6. Oil ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ba498f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì²˜ë¦¬ í›„ Train ê²°ì¸¡ì¹˜: 0\n",
      "ì²˜ë¦¬ í›„ Test ê²°ì¸¡ì¹˜: 0\n"
     ]
    }
   ],
   "source": [
    "# Oil ê°€ê²© ì •ë³´ ë³‘í•©\n",
    "oil_renamed = oil.rename(columns={'dcoilwtico': 'oil_price'})\n",
    "\n",
    "train = train.merge(oil_renamed, on='date', how='left')\n",
    "test = test.merge(oil_renamed, on='date', how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ì„ í˜• ë³´ê°„\n",
    "train['oil_price'] = train['oil_price'].interpolate(method='linear')\n",
    "test['oil_price'] = test['oil_price'].interpolate(method='linear')\n",
    "\n",
    "# ì—¬ì „ížˆ ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "train['oil_price'].fillna(train['oil_price'].mean(), inplace=True)\n",
    "test['oil_price'].fillna(test['oil_price'].mean(), inplace=True)\n",
    "\n",
    "print(f\"ì²˜ë¦¬ í›„ Train ê²°ì¸¡ì¹˜: {train['oil_price'].isnull().sum()}\")\n",
    "print(f\"ì²˜ë¦¬ í›„ Test ê²°ì¸¡ì¹˜: {test['oil_price'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf11df0b",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ìœ ê°€ ë°ì´í„°ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- ê²½ì œ ì§€í‘œë¡œì„œ ìœ ê°€ëŠ” ì†Œë¹„ íŒ¨í„´ì— ì˜í–¥ì„ ë¯¸ì¹¨\n",
    "- **ê²°ì¸¡ì¹˜ ì²˜ë¦¬ 3ë‹¨ê³„:**\n",
    "  1. `interpolate()`: ì„ í˜• ë³´ê°„ (ê°€ìž¥ ì¼ë°˜ì , ì—°ì†ì„± ìœ ì§€)\n",
    "  2. ë‚¨ì€ ê²°ì¸¡ì¹˜ëŠ” í‰ê· ê°’ìœ¼ë¡œ ì±„ìš°ê¸° (edge case ì²˜ë¦¬)\n",
    "  \n",
    "**ì™œ ì„ í˜• ë³´ê°„?** ìœ ê°€ëŠ” ê¸‰ê²©í•œ ë³€ë™ì´ ì•„ë‹Œ ì—°ì†ì ìœ¼ë¡œ ë³€í•˜ëŠ” ê²½ì œ ì§€í‘œì´ê¸° ë•Œë¬¸\n",
    "\n",
    "**ê²°ê³¼:** oil_price ì»¬ëŸ¼ ì¶”ê°€ (ê²°ì¸¡ì¹˜ 0ê°œ)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37966b6b",
   "metadata": {},
   "source": [
    "## 7. Holidays/Events ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38fc387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train íœ´ì¼ ë¹„ìœ¨: 8.71%\n",
      "Test íœ´ì¼ ë¹„ìœ¨: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# íœ´ì¼ ì •ë³´\n",
    "holidays_national = holidays[holidays['locale'] == 'National'][['date', 'type']].copy()\n",
    "holidays_national.rename(columns={'type': 'holiday_type'}, inplace=True)\n",
    "holidays_national['is_holiday'] = 1\n",
    "\n",
    "# Train, Testì— êµ­ê°€ íœ´ì¼ ì •ë³´ ë³‘í•©\n",
    "train = train.merge(holidays_national[['date', 'is_holiday']], on='date', how='left')\n",
    "test = test.merge(holidays_national[['date', 'is_holiday']], on='date', how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ëŠ” 0 (íœ´ì¼ ì•„ë‹˜)\n",
    "train['is_holiday'].fillna(0, inplace=True)\n",
    "test['is_holiday'].fillna(0, inplace=True)\n",
    "\n",
    "print(f\"Train íœ´ì¼ ë¹„ìœ¨: {train['is_holiday'].sum() / len(train) * 100:.2f}%\")\n",
    "print(f\"Test íœ´ì¼ ë¹„ìœ¨: {test['is_holiday'].sum() / len(test) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95108ea8",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**íœ´ì¼/ì´ë²¤íŠ¸ ì •ë³´ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- êµ­ê°€ íœ´ì¼(National) ë˜ëŠ” ì§€ì—­ íœ´ì¼(Regional) ì •ë³´\n",
    "- **íœ´ì¼ì€ íŒë§¤ì— í° ì˜í–¥**: ë³´í†µ íœ´ì¼ì€ íŒë§¤ ì¦ê°€\n",
    "- **ì „ì²˜ë¦¬ ë°©ì‹:** êµ­ê°€ íœ´ì¼ë§Œ ì‚¬ìš© (ë” ì¼ê´€ì„± ìžˆìŒ)\n",
    "- ê²°ì¸¡ì¹˜ = 0 (íœ´ì¼ì´ ì•„ë‹˜)\n",
    "\n",
    "**Binary feature:** is_holiday âˆˆ {0, 1}\n",
    "- ì´ë ‡ê²Œ ë‹¨ìˆœí•˜ê²Œ í•´ì•¼ ëª¨ë¸ì´ ì‰½ê²Œ í•™ìŠµ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fa37a",
   "metadata": {},
   "source": [
    "## 8. Transactions ì •ë³´ ë³‘í•©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f303a1",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ì¼ì¼ ê±°ëž˜ ê±´ìˆ˜(transactions) ì •ë³´ë¥¼ ë³‘í•©**í•©ë‹ˆë‹¤:\n",
    "- `store_nbr`ì™€ `date` ëª¨ë‘ë¥¼ ê¸°ì¤€ìœ¼ë¡œ merge (í•œ ë§¤ìž¥ í•œ ë‚ ì˜ ê±°ëž˜ ê±´ìˆ˜)\n",
    "- **ê±°ëž˜ ê±´ìˆ˜ëŠ” íŒë§¤ëŸ‰ê³¼ ê°•í•œ ìƒê´€ê´€ê³„**: ì†ë‹˜ì´ ë§Žìœ¼ë©´ íŒë§¤ë„ ë§ŽìŒ\n",
    "- **ê°•ë ¥í•œ ì˜ˆì¸¡ íŠ¹ì„±**\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ ì²˜ë¦¬:**\n",
    "- ê° ë§¤ìž¥ë³„ í‰ê·  ê±°ëž˜ëŸ‰ìœ¼ë¡œ ì±„ìš°ê¸° (ë§¤ìž¥ë§ˆë‹¤ ê±°ëž˜ëŸ‰ì´ ë‹¤ë¥¼ ìˆ˜ ìžˆìœ¼ë¯€ë¡œ)\n",
    "- ë” ì •êµí•œ ì ‘ê·¼: store_nbrë³„ë¡œ ë”°ë¡œ ê³„ì‚°\n",
    "\n",
    "**ê²°ê³¼:** n_transactions ì»¬ëŸ¼ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b008b50e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ê±°ëž˜ëŸ‰ ê²°ì¸¡ì¹˜: 0\n",
      "Test ê±°ëž˜ëŸ‰ ê²°ì¸¡ì¹˜: 0\n"
     ]
    }
   ],
   "source": [
    "# ê±°ëž˜ëŸ‰ ì •ë³´ ë³‘í•©\n",
    "transactions_renamed = transactions.rename(columns={'transactions': 'n_transactions'})\n",
    "\n",
    "train = train.merge(transactions_renamed, on=['date', 'store_nbr'], how='left')\n",
    "test = test.merge(transactions_renamed, on=['date', 'store_nbr'], how='left')\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬: ê° ê°€ê²Œë³„ í‰ê·  ê±°ëž˜ëŸ‰ìœ¼ë¡œ ì±„ìš°ê¸°\n",
    "store_avg_transactions = train.groupby('store_nbr')['n_transactions'].mean()\n",
    "train['n_transactions'].fillna(train['store_nbr'].map(store_avg_transactions), inplace=True)\n",
    "test['n_transactions'].fillna(test['store_nbr'].map(store_avg_transactions), inplace=True)\n",
    "\n",
    "print(f\"Train ê±°ëž˜ëŸ‰ ê²°ì¸¡ì¹˜: {train['n_transactions'].isnull().sum()}\")\n",
    "print(f\"Test ê±°ëž˜ëŸ‰ ê²°ì¸¡ì¹˜: {test['n_transactions'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451e5dd9",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**Lag features (ì§€ì—° íŠ¹ì„±)ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤. ì´ê²ƒì€ **ì‹œê³„ì—´ ì˜ˆì¸¡ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ íŠ¹ì„±**ìž…ë‹ˆë‹¤:\n",
    "\n",
    "**ê°œë…:**\n",
    "- `sales_lag_1`: ì–´ì œì˜ íŒë§¤ëŸ‰ â†’ ì–´ì œê°€ ë§Žìœ¼ë©´ ì˜¤ëŠ˜ë„ ë§Žì„ ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "- `sales_lag_7`: 1ì£¼ì¼ ì „ íŒë§¤ëŸ‰ â†’ ì£¼ê°„ íŒ¨í„´ í•™ìŠµ\n",
    "- `sales_lag_14`: 2ì£¼ ì „ íŒë§¤ëŸ‰ â†’ ê²©ì£¼ íŒ¨í„´\n",
    "- `sales_lag_30`: 30ì¼ ì „ íŒë§¤ëŸ‰ â†’ ì›”ê°„ íŒ¨í„´\n",
    "\n",
    "**ì¤‘ìš”:** `groupby('store_nbr')`ë¡œ **ê° ë§¤ìž¥ë³„ë¡œ ë”°ë¡œ ê³„ì‚°**\n",
    "- ë§¤ìž¥ë³„ë¡œ ë…ë¦½ì ìœ¼ë¡œ shift í•´ì•¼ ì‹œê°„ ìˆœì„œê°€ ì„žì´ì§€ ì•ŠìŒ\n",
    "\n",
    "**ê±°ëž˜ëŸ‰ë„ ë™ì¼í•˜ê²Œ ì²˜ë¦¬** (n_transactions_lag_1 ë“±)\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 8ê°œ (sales/n_transactions Ã— 4ê°œ lags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad9664ee",
   "metadata": {},
   "source": [
    "## 9. Lag íŠ¹ì„± ì¶”ì¶œ (ì‹œê³„ì—´ ì´ì „ ë°ì´í„°)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1d61bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lag features ìƒì„± ì¤‘...\n",
      "âœ“ Lag features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_lag_features(df, target_col='sales', lags=[1, 7, 14, 30]):\n",
    "    \"\"\"Lag features ìƒì„±: ì´ì „ ë‚ ì§œë“¤ì˜ íŒë§¤ëŸ‰\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    for lag in lags:\n",
    "        df[f'{target_col}_lag_{lag}'] = df.groupby('store_nbr')[target_col].shift(lag)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Trainì— Lag features ì¶”ê°€\n",
    "print(\"Lag features ìƒì„± ì¤‘...\")\n",
    "train = create_lag_features(train, target_col='sales', lags=[1, 7, 14, 30])\n",
    "train = create_lag_features(train, target_col='n_transactions', lags=[1, 7, 14, 30])\n",
    "\n",
    "print(\"âœ“ Lag features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd43bc07",
   "metadata": {},
   "source": [
    "## 10. Rolling íŠ¹ì„± ì¶”ì¶œ (ì´ë™ í‰ê·  ë° í‘œì¤€íŽ¸ì°¨)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd742872",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**Rolling features (ì´ë™í†µê³„)ë¥¼ ìƒì„±**í•©ë‹ˆë‹¤. ì´ê²ƒë„ ë§¤ìš° ì¤‘ìš”í•œ íŠ¹ì„±ìž…ë‹ˆë‹¤:\n",
    "\n",
    "**ê° window(7ì¼, 14ì¼, 30ì¼)ë§ˆë‹¤ 4ê°€ì§€ í†µê³„:**\n",
    "- `roll_mean`: ì´ë™í‰ê·  â†’ ì¶”ì„¸(trend) ìº¡ì²˜\n",
    "- `roll_std`: ì´ë™ í‘œì¤€íŽ¸ì°¨ â†’ ë³€ë™ì„±(volatility) \n",
    "- `roll_min`: ìµœì†Ÿê°’ â†’ ìµœì € íŒë§¤ëŸ‰\n",
    "- `roll_max`: ìµœëŒ“ê°’ â†’ ìµœê³  íŒë§¤ëŸ‰\n",
    "\n",
    "**ì˜ˆì‹œ:**\n",
    "```\n",
    "sales_roll_mean_7 = ì§€ë‚œ 7ì¼ê°„ì˜ í‰ê·  íŒë§¤ëŸ‰\n",
    "sales_roll_std_7 = ì§€ë‚œ 7ì¼ê°„ì˜ íŒë§¤ëŸ‰ ë³€ë™ì„±\n",
    "```\n",
    "\n",
    "**min_periods=1:** ì²˜ìŒ ëª‡ í–‰ë„ ê³„ì‚° ê°€ëŠ¥ (ì²˜ìŒ 1ì¼ì€ 1ì¼ í‰ê· )\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 24ê°œ (sales/n_transactions Ã— 3ê°œ windows Ã— 4ê°€ì§€ í†µê³„)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f474b4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rolling features ìƒì„± ì¤‘...\n",
      "âœ“ Rolling features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_rolling_features(df, target_col='sales', windows=[7, 14, 30]):\n",
    "    \"\"\"Rolling statistics ìƒì„±: ì´ë™í‰ê· , í‘œì¤€íŽ¸ì°¨, ìµœì†Œ/ìµœëŒ€ê°’\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    for window in windows:\n",
    "        df[f'{target_col}_roll_mean_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
    "        )\n",
    "        df[f'{target_col}_roll_std_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).std()\n",
    "        )\n",
    "        df[f'{target_col}_roll_min_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).min()\n",
    "        )\n",
    "        df[f'{target_col}_roll_max_{window}'] = df.groupby('store_nbr')[target_col].transform(\n",
    "            lambda x: x.rolling(window=window, min_periods=1).max()\n",
    "        )\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Trainì— Rolling features ì¶”ê°€\n",
    "print(\"Rolling features ìƒì„± ì¤‘...\")\n",
    "train = create_rolling_features(train, target_col='sales', windows=[7, 14, 30])\n",
    "train = create_rolling_features(train, target_col='n_transactions', windows=[7, 14, 30])\n",
    "\n",
    "print(\"âœ“ Rolling features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a24ffd7",
   "metadata": {},
   "source": [
    "## 11. Year-over-Year íŠ¹ì„± (ìž‘ë…„ ê°™ì€ ë‚ ì§œì˜ íŒë§¤ëŸ‰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc3c9fe",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**Year-over-Year (YoY) íŠ¹ì„±ì„ ìƒì„±**í•©ë‹ˆë‹¤. **ê³„ì ˆì„±(seasonality) ìº¡ì²˜**:\n",
    "\n",
    "**ê°œë…:**\n",
    "- `sales_yoy_365`: 365ì¼ ì „(ìž‘ë…„ ê°™ì€ ë‚ )ì˜ íŒë§¤ëŸ‰\n",
    "- ìž‘ë…„ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ê°€ ë§Žì´ íŒ”ë ¸ë‹¤ë©´, ì˜¬í•´ í¬ë¦¬ìŠ¤ë§ˆìŠ¤ë„ ë§Žì´ íŒ”ë¦´ ê°€ëŠ¥ì„± ë†’ìŒ\n",
    "- **ì—°ê°„ ê³„ì ˆ íŒ¨í„´**ì„ ëª¨ë¸ì— ì•Œë ¤ì¤Œ\n",
    "\n",
    "**ìž¥ì :**\n",
    "- ë°ì´í„°ê°€ 3ë…„ (2013~2015)ì´ë¯€ë¡œ 365ì¼ ì „ ë°ì´í„°ê°€ ì¶©ë¶„ížˆ ì¡´ìž¬\n",
    "- íœ´ì¼, í”„ë¡œëª¨ì…˜ ê°™ì€ ì£¼ê¸°ì  ì´ë²¤íŠ¸ ìº¡ì²˜\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜ ì¦ê°€:** 2ê°œ (sales_yoy_365, n_transactions_yoy_365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6e280e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year-over-Year features ìƒì„± ì¤‘...\n",
      "âœ“ YoY features ì¶”ê°€ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "def create_yoy_features(df, target_col='sales'):\n",
    "    \"\"\"Year-over-Year íŠ¹ì„±: 365ì¼ ì „ íŒë§¤ëŸ‰ (ê°™ì€ ê³„ì ˆ)\"\"\"\n",
    "    df = df.sort_values(['store_nbr', 'date']).reset_index(drop=True)\n",
    "    df[f'{target_col}_yoy_365'] = df.groupby('store_nbr')[target_col].shift(365)\n",
    "    return df\n",
    "\n",
    "# Trainì— YoY features ì¶”ê°€\n",
    "print(\"Year-over-Year features ìƒì„± ì¤‘...\")\n",
    "train = create_yoy_features(train, target_col='sales')\n",
    "train = create_yoy_features(train, target_col='n_transactions')\n",
    "\n",
    "print(\"âœ“ YoY features ì¶”ê°€ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f7fd11",
   "metadata": {},
   "source": [
    "## 12. Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7df347f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì¤‘...\n",
      "âœ“ Test ë°ì´í„° ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ\n",
      "\n",
      "ì¶”ê°€ëœ ì´ 34ê°œ íŠ¹ì„±ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...\n",
      "âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# Test ë°ì´í„°ì—ë„ ê°™ì€ íŠ¹ì„±ë“¤ì„ ì¶”ê°€í•˜ë˜, Trainê³¼ì˜ ì—°ì†ì„± ë³´ìž¥\n",
    "print(\"Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì¤‘...\")\n",
    "\n",
    "# Trainê³¼ Testë¥¼ ë³‘í•©í•´ì„œ lag ê³„ì‚°\n",
    "train_test_combined = pd.concat(\n",
    "    [train[['store_nbr', 'date', 'sales', 'n_transactions']], \n",
    "     test[['store_nbr', 'date', 'n_transactions']]], \n",
    "    axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "# ë³‘í•© ë°ì´í„°ì—ì„œ Lag/Rolling/YoY íŠ¹ì„± ìƒì„±\n",
    "train_test_combined = create_lag_features(train_test_combined, target_col='sales', lags=[1, 7, 14, 30])\n",
    "train_test_combined = create_lag_features(train_test_combined, target_col='n_transactions', lags=[1, 7, 14, 30])\n",
    "train_test_combined = create_rolling_features(train_test_combined, target_col='sales', windows=[7, 14, 30])\n",
    "train_test_combined = create_rolling_features(train_test_combined, target_col='n_transactions', windows=[7, 14, 30])\n",
    "train_test_combined = create_yoy_features(train_test_combined, target_col='sales')\n",
    "train_test_combined = create_yoy_features(train_test_combined, target_col='n_transactions')\n",
    "\n",
    "# Test ë¶€ë¶„ë§Œ ì¶”ì¶œ\n",
    "test_lag_features = train_test_combined[train_test_combined.index >= len(train)].copy()\n",
    "test_lag_features = test_lag_features.drop(columns=['sales', 'n_transactions'], errors='ignore')\n",
    "\n",
    "# Testì— íŠ¹ì„± ì¶”ê°€\n",
    "for col in test_lag_features.columns:\n",
    "    if col not in test.columns and col != 'date' and col != 'store_nbr':\n",
    "        test[col] = test_lag_features[col].values\n",
    "\n",
    "print(\"âœ“ Test ë°ì´í„° ì‹œê³„ì—´ íŠ¹ì„± ì¶”ê°€ ì™„ë£Œ\")\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬\n",
    "lag_cols = [col for col in train.columns if 'lag' in col or 'roll' in col or 'yoy' in col]\n",
    "print(f\"\\nì¶”ê°€ëœ ì´ {len(lag_cols)}ê°œ íŠ¹ì„±ì˜ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì¤‘...\")\n",
    "\n",
    "for col in lag_cols:\n",
    "    if col in train.columns:\n",
    "        fill_value = train.groupby('store_nbr')[col].transform('mean')\n",
    "        train[col].fillna(fill_value, inplace=True)\n",
    "        train[col].fillna(train[col].mean(), inplace=True)\n",
    "    \n",
    "    if col in test.columns:\n",
    "        fill_value = test.groupby('store_nbr')[col].transform('mean')\n",
    "        test[col].fillna(fill_value, inplace=True)\n",
    "        test[col].fillna(test[col].mean(), inplace=True)\n",
    "\n",
    "print(\"âœ“ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4387f690",
   "metadata": {},
   "source": [
    "## 13. Categorical íŠ¹ì„± ì¸ì½”ë”©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cd23b6",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**Test ë°ì´í„°ì— ì‹œê³„ì—´ íŠ¹ì„±ì„ ì¶”ê°€**í•©ë‹ˆë‹¤. ì´ê²ƒì´ ì¤‘ìš”í•œ ì´ìœ :\n",
    "\n",
    "**ë¬¸ì œ:** Test ë°ì´í„°ì˜ lagë¥¼ ê³„ì‚°í•˜ë ¤ë©´ Trainì˜ ë§ˆì§€ë§‰ ë°ì´í„°ê°€ í•„ìš”\n",
    "- `test_lag_1` = testì˜ ì–´ì œ íŒë§¤ëŸ‰ì¸ë°, ê·¸ ì–´ì œëŠ” Trainì˜ ë§ˆì§€ë§‰ ë‚ ì¼ ìˆ˜ ìžˆìŒ\n",
    "- Testë§Œìœ¼ë¡œëŠ” ê³„ì‚° ë¶ˆê°€ëŠ¥!\n",
    "\n",
    "**í•´ê²°ë²•:**\n",
    "1. Train + Testë¥¼ **ì‹œê°„ìˆœìœ¼ë¡œ ì—°ê²°**\n",
    "2. ì´ ë³‘í•© ë°ì´í„°ì—ì„œ lag/rolling/yoy íŠ¹ì„± ê³„ì‚°\n",
    "3. Test ë¶€ë¶„ë§Œ ì¶”ì¶œí•˜ì—¬ ì›ëž˜ Test ë°ì´í„°ì— ë³‘í•©\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ ì²˜ë¦¬:**\n",
    "- ì²˜ìŒ ëª‡ í–‰ì˜ lagê°’ì€ `groupby('store_nbr').transform('mean')` ì‚¬ìš©\n",
    "- ê° ë§¤ìž¥ë³„ í‰ê· ìœ¼ë¡œ ê²°ì¸¡ì¹˜ ì±„ìš°ê¸° (ì „ì²´ í‰ê· ë³´ë‹¤ ì •í™•í•¨)\n",
    "\n",
    "**ê²°ê³¼:** Testë„ Trainê³¼ ë™ì¼í•œ íŠ¹ì„± ê°œìˆ˜ë¥¼ ê°€ì§"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d4208ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì¹´í…Œê³ ë¦¬ ê°’ ê°œìˆ˜:\n",
      "type: 5\n",
      "family: 33\n",
      "\n",
      "Train shape: (3008016, 97)\n",
      "Test shape: (28512, 96)\n"
     ]
    }
   ],
   "source": [
    "# ì¹´í…Œê³ ë¦¬ íŠ¹ì„± í™•ì¸\n",
    "categorical_cols = ['type', 'family']\n",
    "\n",
    "print(\"ì¹´í…Œê³ ë¦¬ ê°’ ê°œìˆ˜:\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"{col}: {train[col].nunique()}\")\n",
    "\n",
    "# One-hot encoding\n",
    "train = pd.get_dummies(train, columns=categorical_cols, drop_first=False)\n",
    "test = pd.get_dummies(test, columns=categorical_cols, drop_first=False)\n",
    "\n",
    "# Trainê³¼ Testì˜ ì»¬ëŸ¼ ë§žì¶”ê¸°\n",
    "train_cols = set(train.columns)\n",
    "test_cols = set(test.columns)\n",
    "\n",
    "for col in test_cols - train_cols:\n",
    "    test.drop(col, axis=1, inplace=True)\n",
    "\n",
    "for col in train_cols - test_cols:\n",
    "    test[col] = 0\n",
    "\n",
    "test = test[train.columns.drop('sales', errors='ignore')]\n",
    "\n",
    "print(f\"\\nTrain shape: {train.shape}\")\n",
    "print(f\"Test shape: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529da478",
   "metadata": {},
   "source": [
    "## 14. ê²°ì¸¡ì¹˜ ìµœì¢… í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be7f64",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ë²”ì£¼í˜•(Categorical) íŠ¹ì„±ì„ ì¸ì½”ë”©**í•©ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì€ ìˆ«ìžë§Œ ì´í•´í•˜ê¸° ë•Œë¬¸:\n",
    "\n",
    "**ë²”ì£¼í˜• íŠ¹ì„±:**\n",
    "- `type`: ë§¤ìž¥ ìœ í˜• (A, B, C, D) â†’ 4ê°œ ê°’\n",
    "- `family`: ìƒí’ˆ ë¶„ë¥˜ (33ê°œ ê°’: Beverages, Dairy, Frozen Food ë“±)\n",
    "\n",
    "**One-hot encoding:**\n",
    "```python\n",
    "type_A=1, type_B=0, type_C=0, type_D=0  # type='A'ì¸ ê²½ìš°\n",
    "family_Beverages=1, family_Dairy=0, ...  # family='Beverages'ì¸ ê²½ìš°\n",
    "```\n",
    "\n",
    "**Trainê³¼ Test ì»¬ëŸ¼ ë§žì¶”ê¸°:**\n",
    "- Testì—ë§Œ ìžˆëŠ” ì¹´í…Œê³ ë¦¬ ì œê±° (Trainê³¼ ê°™ì€ ë²”ì£¼ë§Œ ìœ ì§€)\n",
    "- Trainì—ë§Œ ìžˆëŠ” ì¹´í…Œê³ ë¦¬ëŠ” Testì— 0ìœ¼ë¡œ ì¶”ê°€ (ëª¨ë‘ False)\n",
    "- ì»¬ëŸ¼ ìˆœì„œë¥¼ ë™ì¼í•˜ê²Œ ì •ë ¬\n",
    "\n",
    "**íŠ¹ì„± ê°œìˆ˜:** 4ê°œ(type) + 33ê°œ(family) = 37ê°œ ì¶”ê°€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a35991e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Train ê²°ì¸¡ì¹˜ ===\n",
      "Series([], dtype: int64)\n",
      "\n",
      "=== Test ê²°ì¸¡ì¹˜ ===\n",
      "Series([], dtype: int64)\n",
      "\n",
      "âœ“ Trainì— ê²°ì¸¡ì¹˜ ì—†ìŒ\n",
      "âœ“ Testì— ê²°ì¸¡ì¹˜ ì—†ìŒ\n"
     ]
    }
   ],
   "source": [
    "print(\"=== Train ê²°ì¸¡ì¹˜ ===\")\n",
    "missing_train = train.isnull().sum()\n",
    "print(missing_train[missing_train > 0])\n",
    "\n",
    "print(\"\\n=== Test ê²°ì¸¡ì¹˜ ===\")\n",
    "missing_test = test.isnull().sum()\n",
    "print(missing_test[missing_test > 0])\n",
    "\n",
    "if missing_train.sum() == 0:\n",
    "    print(\"\\nâœ“ Trainì— ê²°ì¸¡ì¹˜ ì—†ìŒ\")\n",
    "if missing_test.sum() == 0:\n",
    "    print(\"âœ“ Testì— ê²°ì¸¡ì¹˜ ì—†ìŒ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e233e0",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ê²°ì¸¡ì¹˜(Missing values)ë¥¼ ìµœì¢… í™•ì¸**í•©ë‹ˆë‹¤. ëª¨ë¸ í•™ìŠµ ì „ í•„ìˆ˜ ê²€ì‚¬:\n",
    "\n",
    "**ê²°ì¸¡ì¹˜ê°€ ë‚¨ì•„ìžˆìœ¼ë©´:**\n",
    "- XGBoost ë“± ì¼ë¶€ ëª¨ë¸: ìžë™ ì²˜ë¦¬ (ì„±ëŠ¥ ì €í•˜)\n",
    "- ë‹¤ë¥¸ ëª¨ë¸ë“¤: ì—ëŸ¬ ë°œìƒ\n",
    "\n",
    "**í™•ì¸ í•­ëª©:**\n",
    "1. Trainì˜ ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜\n",
    "2. Testì˜ ê° ì»¬ëŸ¼ë³„ ê²°ì¸¡ì¹˜ ê°œìˆ˜\n",
    "3. ê²°ì¸¡ì¹˜ê°€ ìžˆìœ¼ë©´ ì–´ë””ì„œ ì™”ëŠ”ì§€ ì¶”ì \n",
    "\n",
    "**ì´ìƒì ì¸ ìƒíƒœ:** ëª¨ë“  ê²°ì¸¡ì¹˜ = 0\n",
    "- ì•žì„œ interpolate, fillnaë¡œ ì²˜ë¦¬í–ˆê¸° ë•Œë¬¸ì— 0ì´ì–´ì•¼ í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6678eaca",
   "metadata": {},
   "source": [
    "## 15. ë°ì´í„° í†µê³„"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25d08392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Train ë°ì´í„° ì •ë³´ ===\n",
      "Shape: (3008016, 97)\n",
      "ì»¬ëŸ¼ ìˆ˜: 97\n",
      "\n",
      "ìˆ˜ì¹˜í˜• íŠ¹ì„± í†µê³„:\n",
      "                 id                           date     store_nbr  \\\n",
      "count  3.008016e+06                        3008016  3.008016e+06   \n",
      "mean   1.501508e+06  2015-04-24 22:50:02.843602688  2.750000e+01   \n",
      "min    0.000000e+00            2013-01-01 00:00:00  1.000000e+00   \n",
      "25%    7.520038e+05            2014-02-27 18:00:00  1.400000e+01   \n",
      "50%    1.502226e+06            2015-04-25 12:00:00  2.750000e+01   \n",
      "75%    2.248883e+06            2016-06-18 06:00:00  4.100000e+01   \n",
      "max    3.000887e+06            2017-08-15 00:00:00  5.400000e+01   \n",
      "std    8.657303e+05                            NaN  1.558579e+01   \n",
      "\n",
      "              sales   onpromotion          year         month           day  \\\n",
      "count  3.008016e+06  3.008016e+06  3.008016e+06  3.008016e+06  3.008016e+06   \n",
      "mean   3.582691e+02  2.609620e+00  2.014839e+03  6.209123e+00  1.561789e+01   \n",
      "min    0.000000e+00  0.000000e+00  2.013000e+03  1.000000e+00  1.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  2.014000e+03  3.000000e+00  8.000000e+00   \n",
      "50%    1.100000e+01  0.000000e+00  2.015000e+03  6.000000e+00  1.600000e+01   \n",
      "75%    1.960000e+02  0.000000e+00  2.016000e+03  9.000000e+00  2.300000e+01   \n",
      "max    1.247170e+05  7.410000e+02  2.017000e+03  1.200000e+01  3.100000e+01   \n",
      "std    1.103511e+03  1.226308e+01  1.344969e+00  3.384974e+00  8.799659e+00   \n",
      "\n",
      "            quarter     dayofweek  ...  n_transactions_roll_mean_14  \\\n",
      "count  3.008016e+06  3.008016e+06  ...                 3.008016e+06   \n",
      "mean   2.410545e+00  3.002370e+00  ...                 1.672260e+03   \n",
      "min    1.000000e+00  0.000000e+00  ...                 5.000000e+00   \n",
      "25%    1.000000e+00  1.000000e+00  ...                 1.053286e+03   \n",
      "50%    2.000000e+00  3.000000e+00  ...                 1.375529e+03   \n",
      "75%    3.000000e+00  5.000000e+00  ...                 2.073000e+03   \n",
      "max    4.000000e+00  6.000000e+00  ...                 8.359000e+03   \n",
      "std    1.099465e+00  2.001775e+00  ...                 9.378308e+02   \n",
      "\n",
      "       n_transactions_roll_std_14  n_transactions_roll_min_14  \\\n",
      "count                3.008016e+06                3.008016e+06   \n",
      "mean                 3.446347e+01                1.632191e+03   \n",
      "min                  0.000000e+00                5.000000e+00   \n",
      "25%                  0.000000e+00                1.021000e+03   \n",
      "50%                  0.000000e+00                1.341000e+03   \n",
      "75%                  3.033195e+01                2.029000e+03   \n",
      "max                  1.934364e+03                8.359000e+03   \n",
      "std                  8.526980e+01                9.161017e+02   \n",
      "\n",
      "       n_transactions_roll_max_14  n_transactions_roll_mean_30  \\\n",
      "count                3.008016e+06                 3.008016e+06   \n",
      "mean                 1.712330e+03                 1.672270e+03   \n",
      "min                  5.000000e+00                 5.000000e+00   \n",
      "25%                  1.081000e+03                 1.057800e+03   \n",
      "50%                  1.409000e+03                 1.376500e+03   \n",
      "75%                  2.122000e+03                 2.070200e+03   \n",
      "max                  8.359000e+03                 8.359000e+03   \n",
      "std                  9.655612e+02                 9.330048e+02   \n",
      "\n",
      "       n_transactions_roll_std_30  n_transactions_roll_min_30  \\\n",
      "count                3.008016e+06                3.008016e+06   \n",
      "mean                 7.339199e+01                1.582884e+03   \n",
      "min                  0.000000e+00                5.000000e+00   \n",
      "25%                  6.048083e+00                9.980000e+02   \n",
      "50%                  3.633226e+01                1.304000e+03   \n",
      "75%                  9.172926e+01                1.966000e+03   \n",
      "max                  1.895866e+03                8.359000e+03   \n",
      "std                  1.099770e+02                8.806837e+02   \n",
      "\n",
      "       n_transactions_roll_max_30  sales_yoy_365  n_transactions_yoy_365  \n",
      "count                3.008016e+06   3.008016e+06            3.008016e+06  \n",
      "mean                 1.761655e+03   3.576441e+02            1.672468e+03  \n",
      "min                  5.000000e+00   0.000000e+00            5.000000e+00  \n",
      "25%                  1.116180e+03   0.000000e+00            1.050000e+03  \n",
      "50%                  1.453000e+03   1.100000e+01            1.375000e+03  \n",
      "75%                  2.178000e+03   2.009140e+02            2.075000e+03  \n",
      "max                  8.359000e+03   1.247170e+05            8.359000e+03  \n",
      "std                  9.915692e+02   1.099230e+03            9.417604e+02  \n",
      "\n",
      "[8 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Train ë°ì´í„° ì •ë³´ ===\")\n",
    "print(f\"Shape: {train.shape}\")\n",
    "print(f\"ì»¬ëŸ¼ ìˆ˜: {len(train.columns)}\")\n",
    "print(f\"\\nìˆ˜ì¹˜í˜• íŠ¹ì„± í†µê³„:\")\n",
    "print(train.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cefac0c",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ë°ì´í„°ì˜ í†µê³„ ì •ë³´ë¥¼ ì¶œë ¥**í•©ë‹ˆë‹¤. ë°ì´í„° ë¶„í¬ë¥¼ ì´í•´í•˜ëŠ” ê²ƒì´ ì¤‘ìš”:\n",
    "\n",
    "**í™•ì¸ í•­ëª©:**\n",
    "- `count`: ë¹„ê²°ì¸¡ì¹˜ ê°œìˆ˜ (ëŒ€ë¶€ë¶„ ê°™ì•„ì•¼ í•¨)\n",
    "- `mean`: í‰ê·  íŒë§¤ëŸ‰ (ìŠ¤ì¼€ì¼ ê°ìž¡ê¸°)\n",
    "- `std`: í‘œì¤€íŽ¸ì°¨ (íŒë§¤ëŸ‰ ë³€ë™ì„±)\n",
    "- `min/max`: ìµœì†Œ/ìµœëŒ€ê°’ (ì´ìƒì¹˜ í™•ì¸)\n",
    "- `25%, 50%, 75%`: ì‚¬ë¶„ìœ„ìˆ˜ (ë¶„í¬ ëª¨ì–‘)\n",
    "\n",
    "**ì´ìƒì¹˜ ì—¬ë¶€ í™•ì¸:**\n",
    "- minì´ 0ì´ìƒ? â†’ íŒë§¤ëŸ‰ì´ ìŒìˆ˜ì¼ ìˆ˜ ì—†ìŒ âœ“\n",
    "- maxê°€ ë„ˆë¬´ í¬ì§€ëŠ” ì•Šì€ê°€? â†’ í”„ë¡œëª¨ì…˜ì´ë‚˜ í° ë§¤ìž¥ì¼ ìˆ˜ ìžˆìŒ\n",
    "\n",
    "**ìŠ¤ì¼€ì¼ë§ í•„ìš”?** \n",
    "- ì´í›„ ëª¨ë¸ í›ˆë ¨ ì‹œ íŠ¸ë¦¬ ê¸°ë°˜ ëª¨ë¸(XGBoost)ì€ ìŠ¤ì¼€ì¼ë§ ë¶ˆí•„ìš”\n",
    "- ì‹ ê²½ë§ ë“±ì€ í•„ìš”í•  ìˆ˜ ìžˆìŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1db5f7",
   "metadata": {},
   "source": [
    "## 16. ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9fe2df86",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain_processed.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test.to_csv(\u001b[33m'\u001b[39m\u001b[33mtest_processed.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mâœ“ train_processed.csv ì €ìž¥ ì™„ë£Œ\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:270\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[32m    252\u001b[39m     \u001b[38;5;28mself\u001b[39m.filepath_or_buffer,\n\u001b[32m    253\u001b[39m     \u001b[38;5;28mself\u001b[39m.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:275\u001b[39m, in \u001b[36mCSVFormatter._save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._need_to_save_header:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._save_header()\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:313\u001b[39m, in \u001b[36mCSVFormatter._save_body\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_i >= end_i:\n\u001b[32m    312\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_save_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_i\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:320\u001b[39m, in \u001b[36mCSVFormatter._save_chunk\u001b[39m\u001b[34m(self, start_i, end_i)\u001b[39m\n\u001b[32m    317\u001b[39m slicer = \u001b[38;5;28mslice\u001b[39m(start_i, end_i)\n\u001b[32m    318\u001b[39m df = \u001b[38;5;28mself\u001b[39m.obj.iloc[slicer]\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m res = \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_number_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m data = \u001b[38;5;28mlist\u001b[39m(res._iter_column_arrays())\n\u001b[32m    323\u001b[39m ix = \u001b[38;5;28mself\u001b[39m.data_index[slicer]._get_values_for_csv(**\u001b[38;5;28mself\u001b[39m._number_format)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:1414\u001b[39m, in \u001b[36mDataFrame._get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m   1404\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_values_for_csv\u001b[39m(\n\u001b[32m   1405\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1406\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1412\u001b[39m ) -> Self:\n\u001b[32m   1413\u001b[39m     \u001b[38;5;66;03m# helper used by to_csv\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1414\u001b[39m     mgr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_values_for_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1415\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1420\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1421\u001b[39m     \u001b[38;5;66;03m# error: Incompatible return value type (got \"DataFrame\", expected \"Self\")\u001b[39;00m\n\u001b[32m   1422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(mgr, axes=mgr.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:485\u001b[39m, in \u001b[36mBaseBlockManager.get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_values_for_csv\u001b[39m(\n\u001b[32m    479\u001b[39m     \u001b[38;5;28mself\u001b[39m, *, float_format, date_format, decimal, na_rep: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33mnan\u001b[39m\u001b[33m\"\u001b[39m, quoting=\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    480\u001b[39m ) -> Self:\n\u001b[32m    481\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[33;03m    Convert values to native types (strings / python objects) that are used\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[33;03m    in formatting (repr / csv).\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget_values_for_csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    487\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_rep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m        \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfloat_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecimal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:814\u001b[39m, in \u001b[36mBlock.get_values_for_csv\u001b[39m\u001b[34m(self, float_format, date_format, decimal, na_rep, quoting)\u001b[39m\n\u001b[32m    805\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"convert to our native types format\"\"\"\u001b[39;00m\n\u001b[32m    806\u001b[39m result = get_values_for_csv(\n\u001b[32m    807\u001b[39m     \u001b[38;5;28mself\u001b[39m.values,\n\u001b[32m    808\u001b[39m     na_rep=na_rep,\n\u001b[32m   (...)\u001b[39m\u001b[32m    812\u001b[39m     decimal=decimal,\n\u001b[32m    813\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m814\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmake_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\seogu\\Desktop\\ìœ í‹¸\\kaggle\\store-sales-time-series-forecasting\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:276\u001b[39m, in \u001b[36mBlock.make_block\u001b[39m\u001b[34m(self, values, placement, refs)\u001b[39m\n\u001b[32m    272\u001b[39m \u001b[38;5;129m@mgr_locs\u001b[39m.setter\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmgr_locs\u001b[39m(\u001b[38;5;28mself\u001b[39m, new_mgr_locs: BlockPlacement) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    274\u001b[39m     \u001b[38;5;28mself\u001b[39m._mgr_locs = new_mgr_locs\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;129m@final\u001b[39m\n\u001b[32m    277\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mmake_block\u001b[39m(\n\u001b[32m    278\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    279\u001b[39m     values,\n\u001b[32m    280\u001b[39m     placement: BlockPlacement | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    281\u001b[39m     refs: BlockValuesRefs | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    282\u001b[39m ) -> Block:\n\u001b[32m    283\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    284\u001b[39m \u001b[33;03m    Create a new block, with type inference propagate any values that are\u001b[39;00m\n\u001b[32m    285\u001b[39m \u001b[33;03m    not specified\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    287\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m placement \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ìž¥\n",
    "train.to_csv('train_processed.csv', index=False)\n",
    "test.to_csv('test_processed.csv', index=False)\n",
    "\n",
    "print(\"âœ“ train_processed.csv ì €ìž¥ ì™„ë£Œ\")\n",
    "print(\"âœ“ test_processed.csv ì €ìž¥ ì™„ë£Œ\")\n",
    "print(f\"\\nì´ {len(train)} í–‰ì˜ í•™ìŠµ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")\n",
    "print(f\"ì´ {len(test)} í–‰ì˜ í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c325f",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ì „ì²˜ë¦¬ëœ ë°ì´í„°ë¥¼ CSVë¡œ ì €ìž¥**í•©ë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„(ëª¨ë¸ í›ˆë ¨)ì—ì„œ ì‚¬ìš©:\n",
    "\n",
    "**ì €ìž¥í•˜ëŠ” ì´ìœ :**\n",
    "1. **ìž¬ì‚¬ìš©ì„±**: ëª¨ë¸ í›ˆë ¨í•  ë•Œë§ˆë‹¤ ì´ ì „ì²˜ë¦¬ ê³¼ì •ì„ ë°˜ë³µí•  í•„ìš” ì—†ìŒ\n",
    "2. **ì‹œê°„ ì ˆì•½**: ë‹¤ìŒ ë…¸íŠ¸ë¶ì—ì„œ ë°”ë¡œ ëª¨ë¸ í›ˆë ¨ ê°€ëŠ¥\n",
    "3. **ì¼ê´€ì„±**: ëª¨ë“  ë¶„ì„ì´ ë™ì¼í•œ ë°ì´í„°ì…‹ ê¸°ë°˜\n",
    "\n",
    "**ì €ìž¥ë˜ëŠ” íŒŒì¼:**\n",
    "- `train_processed.csv`: í•™ìŠµ ë°ì´í„° (3,000,888 í–‰ Ã— ì•½ 90ì—´)\n",
    "- `test_processed.csv`: í…ŒìŠ¤íŠ¸ ë°ì´í„° (28,512 í–‰ Ã— ì•½ 90ì—´)\n",
    "\n",
    "**ì»¬ëŸ¼ ì •ë³´:**\n",
    "- Train: `sales` (target) í¬í•¨\n",
    "- Test: `sales` ë¯¸í¬í•¨ (ì˜ˆì¸¡í•´ì•¼ í•  ê°’)\n",
    "- ë‘˜ ë‹¤: `date`, `store_nbr` ë“± ë©”íƒ€ë°ì´í„° í¬í•¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa41302",
   "metadata": {},
   "source": [
    "## 17. íŠ¹ì„± ëª©ë¡ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356aec92",
   "metadata": {},
   "source": [
    "### ðŸ“š ì„¤ëª…\n",
    "\n",
    "**ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ëª¨ë“  íŠ¹ì„±ì„ ë‚˜ì—´**í•©ë‹ˆë‹¤. ëª¨ë¸ í›ˆë ¨ì˜ ìž…ë ¥ íŠ¹ì„± í™•ì¸:\n",
    "\n",
    "**íŠ¹ì„± ì œì™¸ ì‚¬í•­:**\n",
    "- `sales`: ì˜ˆì¸¡ ëŒ€ìƒ (ìž…ë ¥ì´ ì•„ë‹˜)\n",
    "- `date`: ì´ë¯¸ year/month/dayë¡œ ë¶„í•´ë¨\n",
    "- `id`: ê³ ìœ  ì‹ë³„ìž (ì˜ˆì¸¡ ì„±ëŠ¥ê³¼ ë¬´ê´€)\n",
    "\n",
    "**íŠ¹ì„± ì¢…ë¥˜:**\n",
    "1. **ë‚ ì§œ íŠ¹ì„±**: year, month, day, dayofweek, month_sin/cos ë“± (13ê°œ)\n",
    "2. **ë§¤ìž¥ íŠ¹ì„±**: store_nbr, type_A/B/C/D, cluster, city ë“± (10+ê°œ)\n",
    "3. **ê²½ì œ íŠ¹ì„±**: oil_price (1ê°œ)\n",
    "4. **íœ´ì¼**: is_holiday (1ê°œ)\n",
    "5. **ê±°ëž˜ëŸ‰**: n_transactions (1ê°œ)\n",
    "6. **Lag**: sales_lag_1/7/14/30, n_transactions_lag_1/7/14/30 (8ê°œ)\n",
    "7. **Rolling**: roll_mean/std/min/max (24ê°œ)\n",
    "8. **YoY**: yoy_365 (2ê°œ)\n",
    "9. **ë²”ì£¼í˜•**: family_Beverages, ... (33ê°œ)\n",
    "\n",
    "**ì´ íŠ¹ì„± ìˆ˜: ì•½ 90~100ê°œ**\n",
    "- ì´ˆê¸° ì»¬ëŸ¼ 18ê°œ â†’ íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§ì„ í†µí•´ 5ë°° ì´ìƒ ì¦ê°€\n",
    "- ì´ê²ƒì´ ëª¨ë¸ ì„±ëŠ¥ì˜ í•µì‹¬!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beb2e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainì—ì„œ target ì œì™¸í•œ íŠ¹ì„± ëª©ë¡\n",
    "feature_cols = [col for col in train.columns if col not in ['sales', 'date', 'id']]\n",
    "\n",
    "print(f\"\\nì´ íŠ¹ì„± ê°œìˆ˜: {len(feature_cols)}\")\n",
    "print(\"\\níŠ¹ì„± ëª©ë¡:\")\n",
    "for i, col in enumerate(feature_cols, 1):\n",
    "    print(f\"{i}. {col}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
